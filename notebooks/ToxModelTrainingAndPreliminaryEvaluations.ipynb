{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Team Detox Capstone Project**\n",
        "## -- Model Grid Searches and Preliminary Evaluations\n",
        "## *Clean Notebook* (Amy) "
      ],
      "metadata": {
        "id": "oBcd6NOBF_AL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install DeepChem (and rdkit)"
      ],
      "metadata": {
        "id": "RzDKjp9BVL9r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2313ZdVDTJ-d",
        "outputId": "0089ece1-7c02-43d9-ec93-5e15049894e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting deepchem==2.7.2.dev20230209144634\n",
            "  Downloading deepchem-2.7.2.dev20230209144634-py3-none-any.whl (709 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m709.7/709.7 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from deepchem==2.7.2.dev20230209144634) (1.2.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from deepchem==2.7.2.dev20230209144634) (1.2.2)\n",
            "Collecting rdkit\n",
            "  Downloading rdkit-2022.9.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.4/29.4 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.9/dist-packages (from deepchem==2.7.2.dev20230209144634) (1.22.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from deepchem==2.7.2.dev20230209144634) (1.5.3)\n",
            "Collecting scipy<1.9\n",
            "  Downloading scipy-1.8.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->deepchem==2.7.2.dev20230209144634) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->deepchem==2.7.2.dev20230209144634) (2.8.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.9/dist-packages (from rdkit->deepchem==2.7.2.dev20230209144634) (8.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->deepchem==2.7.2.dev20230209144634) (3.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->deepchem==2.7.2.dev20230209144634) (1.16.0)\n",
            "Installing collected packages: scipy, rdkit, deepchem\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.10.1\n",
            "    Uninstalling scipy-1.10.1:\n",
            "      Successfully uninstalled scipy-1.10.1\n",
            "Successfully installed deepchem-2.7.2.dev20230209144634 rdkit-2022.9.5 scipy-1.8.1\n"
          ]
        }
      ],
      "source": [
        "!pip install deepchem==2.7.2.dev20230209144634"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAjzse0NLKN1",
        "outputId": "c7971f52-53fd-4b63-890b-01d4c12337d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.9/dist-packages (2.12.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow) (23.0)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.22.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow) (67.6.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.53.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.4.7)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.2.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.12.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.32.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (16.0.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (23.3.3)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.9/dist-packages (from jax>=0.3.15->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.9/dist-packages (from jax>=0.3.15->tensorflow) (0.0.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.27.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow) (6.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.12)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import libraries"
      ],
      "metadata": {
        "id": "58pfgEBpF-99"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import deepchem as dc"
      ],
      "metadata": {
        "id": "pMaLVDWhfivB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b83a3b2-e97e-4bc2-bdb8-6550a6eb6bf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:deepchem.models.torch_models:Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'torch_geometric'\n",
            "WARNING:deepchem.models:Skipped loading modules with pytorch-geometric dependency, missing a dependency. cannot import name 'DMPNN' from 'deepchem.models.torch_models' (/usr/local/lib/python3.9/dist-packages/deepchem/models/torch_models/__init__.py)\n",
            "WARNING:deepchem.models:Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'pytorch_lightning'\n",
            "WARNING:deepchem.models:Skipped loading some Jax models, missing a dependency. No module named 'haiku'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print timestamp\n",
        "from datetime import datetime\n",
        "import pytz\n",
        "date_now = datetime.now().date()\n",
        "time_SF = datetime.now(pytz.timezone('America/Vancouver'))\n",
        "\n",
        "print(\"Timestamp:\", date_now, datetime.now(pytz.timezone('America/Vancouver')).strftime(\"%H:%M:%S\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeUAYT_aejm-",
        "outputId": "23e75680-20b5-4fd9-da38-2d8fd2de80eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timestamp: 2023-04-13 22:37:15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train 7 Deep Learning models from DeepChem library\n",
        "Main reference: https://deepchem.readthedocs.io/en/latest/api_reference/models.html"
      ],
      "metadata": {
        "id": "wwy0ZPahV47A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model #1: Multitask Classifier with Circular Fingerprints (ECFPs)"
      ],
      "metadata": {
        "id": "cpfEtGzgQqbV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load, featurize and transform data: break SMILES to ECFP features"
      ],
      "metadata": {
        "id": "M_FVIux6M0fu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load Tox21 dataset, note this Deepchem function includes featurizer and transformer \n",
        "#This took 14s\n",
        "tox21_tasks1, tox21_datasets1, transformers1 = dc.molnet.load_tox21(featurizer=dc.feat.CircularFingerprint(size=1024, radius=4))\n",
        "\n",
        "#train test validation split\n",
        "train_dataset1, valid_dataset1, test_dataset1 = tox21_datasets1\n",
        "train_dataset1\n",
        "#Looks like we got 6264 compounds in the training set with 1024 fingerprints/features and 12 assays/tasks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ysVKSimVLQX",
        "outputId": "af539a16-7c54-4300-87ee-61c0d547be5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[05:36:06] WARNING: not removing hydrogen atom without neighbors\n",
            "[05:36:17] WARNING: not removing hydrogen atom without neighbors\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<DiskDataset X.shape: (6264, 1024), y.shape: (6264, 12), w.shape: (6264, 12), task_names: ['NR-AR' 'NR-AR-LBD' 'NR-AhR' ... 'SR-HSE' 'SR-MMP' 'SR-p53']>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Grid Search for Model #1: Multitask classifer via ECFP\n",
        "#### Use train and test datasets to evaluate preliminary scores"
      ],
      "metadata": {
        "id": "SgxWO6ef28Lm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define function for grid search\n",
        "Reference: https://deepchem.readthedocs.io/en/latest/api_reference/hyper.html"
      ],
      "metadata": {
        "id": "zmbYwluPLlgg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Took 50s \n",
        "def model_builder(**model_params):\n",
        "  dropout = model_params['dropout']\n",
        "  layer_sizes = model_params['layer_sizes']\n",
        "  learning_rate = model_params['learning_rate']\n",
        "  model = dc.models.MultitaskClassifier(n_tasks=12, n_features=1024, layer_sizes=layer_sizes, learning_rate=learning_rate, dropouts=dropout, random_state=2) \n",
        "  return model\n",
        "\n",
        "params = {\n",
        "    'dropout':[0,0.2,0.3, 0.5],\n",
        "    'layer_sizes':[[500],[1000],[1000, 1000]],\n",
        "    'learning_rate':[0.0005, 0.001, 0.005]\n",
        "    }\n",
        "optimizer = dc.hyper.GridHyperparamOpt(model_builder)\n",
        "metric = dc.metrics.Metric(dc.metrics.roc_auc_score, np.mean, mode=\"classification\")\n",
        "\n",
        "best_model_mcfp, best_hyperparams_mcfp, all_results_mcfp = optimizer.hyperparam_search(params, train_dataset1, test_dataset1, metric)\n",
        "\n",
        "print(\"Timestamp:\", date_now, datetime.now(pytz.timezone('America/Vancouver')).strftime(\"%H:%M:%S\"))\n",
        "\n",
        "print(best_hyperparams_mcfp)#this jumps between {'dropout': 0.5, 'layer_sizes': [500], 'learning_rate': 0.001} vs. the one shown below\n",
        "all_results_mcfp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qSx7ii-3DUu",
        "outputId": "e00a881f-ec65-4232-b410-f79354b5c124"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timestamp: 2023-03-23 15:49:57\n",
            "{'dropout': 0.5, 'layer_sizes': [1000, 1000], 'learning_rate': 0.0005}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'_dropout_0_layer_sizes[500]_learning_rate_0.000500': 0.6693249557043642,\n",
              " '_dropout_0_layer_sizes[500]_learning_rate_0.001000': 0.6604961596234661,\n",
              " '_dropout_0_layer_sizes[500]_learning_rate_0.005000': 0.6614832798835203,\n",
              " '_dropout_0_layer_sizes[1000]_learning_rate_0.000500': 0.6698910174053948,\n",
              " '_dropout_0_layer_sizes[1000]_learning_rate_0.001000': 0.6583008045053889,\n",
              " '_dropout_0_layer_sizes[1000]_learning_rate_0.005000': 0.6606812157049596,\n",
              " '_dropout_0_layer_sizes[1000, 1000]_learning_rate_0.000500': 0.6683050360548455,\n",
              " '_dropout_0_layer_sizes[1000, 1000]_learning_rate_0.001000': 0.6649326418496367,\n",
              " '_dropout_0_layer_sizes[1000, 1000]_learning_rate_0.005000': 0.6596857650135964,\n",
              " '_dropout_0.200000_layer_sizes[500]_learning_rate_0.000500': 0.6801909933320922,\n",
              " '_dropout_0.200000_layer_sizes[500]_learning_rate_0.001000': 0.6747460241664737,\n",
              " '_dropout_0.200000_layer_sizes[500]_learning_rate_0.005000': 0.6623401768529996,\n",
              " '_dropout_0.200000_layer_sizes[1000]_learning_rate_0.000500': 0.6735053958632297,\n",
              " '_dropout_0.200000_layer_sizes[1000]_learning_rate_0.001000': 0.6681558633535937,\n",
              " '_dropout_0.200000_layer_sizes[1000]_learning_rate_0.005000': 0.6647683051645216,\n",
              " '_dropout_0.200000_layer_sizes[1000, 1000]_learning_rate_0.000500': 0.6793209581617291,\n",
              " '_dropout_0.200000_layer_sizes[1000, 1000]_learning_rate_0.001000': 0.6784070398716978,\n",
              " '_dropout_0.200000_layer_sizes[1000, 1000]_learning_rate_0.005000': 0.6672306900474395,\n",
              " '_dropout_0.300000_layer_sizes[500]_learning_rate_0.000500': 0.6831244474896804,\n",
              " '_dropout_0.300000_layer_sizes[500]_learning_rate_0.001000': 0.6760701103279168,\n",
              " '_dropout_0.300000_layer_sizes[500]_learning_rate_0.005000': 0.6618317964915655,\n",
              " '_dropout_0.300000_layer_sizes[1000]_learning_rate_0.000500': 0.6760960874851077,\n",
              " '_dropout_0.300000_layer_sizes[1000]_learning_rate_0.001000': 0.6679862134781606,\n",
              " '_dropout_0.300000_layer_sizes[1000]_learning_rate_0.005000': 0.6681446775839297,\n",
              " '_dropout_0.300000_layer_sizes[1000, 1000]_learning_rate_0.000500': 0.6890809243707094,\n",
              " '_dropout_0.300000_layer_sizes[1000, 1000]_learning_rate_0.001000': 0.6718501446651858,\n",
              " '_dropout_0.300000_layer_sizes[1000, 1000]_learning_rate_0.005000': 0.6716415195347163,\n",
              " '_dropout_0.500000_layer_sizes[500]_learning_rate_0.000500': 0.6885846638976783,\n",
              " '_dropout_0.500000_layer_sizes[500]_learning_rate_0.001000': 0.6828108500001041,\n",
              " '_dropout_0.500000_layer_sizes[500]_learning_rate_0.005000': 0.6783865190931792,\n",
              " '_dropout_0.500000_layer_sizes[1000]_learning_rate_0.000500': 0.6859568426717066,\n",
              " '_dropout_0.500000_layer_sizes[1000]_learning_rate_0.001000': 0.6777103048662415,\n",
              " '_dropout_0.500000_layer_sizes[1000]_learning_rate_0.005000': 0.6751272961949066,\n",
              " '_dropout_0.500000_layer_sizes[1000, 1000]_learning_rate_0.000500': 0.6909131679268915,\n",
              " '_dropout_0.500000_layer_sizes[1000, 1000]_learning_rate_0.001000': 0.6782670624196725,\n",
              " '_dropout_0.500000_layer_sizes[1000, 1000]_learning_rate_0.005000': 0.662035628825526}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Best MultitaskClassifier + ECFP model: save model on G:drive"
      ],
      "metadata": {
        "id": "_h98PN9aIjSS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Took 10s\n",
        "import timeit\n",
        "start_time = timeit.default_timer()\n",
        "\n",
        "model_mccp = dc.models.MultitaskClassifier(n_tasks=12, n_features=1024, layer_sizes=[1000,1000], learning_rate = 0.0005, dropouts=0.5, random_state=2, model_dir='./someDirectory/someFolder') \n",
        "model_mccp.fit(train_dataset1, nb_epoch=50)\n",
        "\n",
        "elapsed = timeit.default_timer() - start_time\n",
        "print(\"Fit time for this cell at 50 epochs: \", elapsed)\n",
        "print(\"Timestamp:\", date_now, datetime.now(pytz.timezone('America/Vancouver')).strftime(\"%H:%M:%S\"))\n",
        "\n",
        "metrics = [dc.metrics.Metric(dc.metrics.roc_auc_score, np.mean, mode=\"classification\"),dc.metrics.Metric(dc.metrics.balanced_accuracy_score, np.mean, mode=\"classification\")]\n",
        "\n",
        "mccp_train_scores = model_mccp.evaluate(train_dataset1, metrics, transformers1)\n",
        "mccp_test_scores = model_mccp.evaluate(test_dataset1, metrics, transformers1)\n",
        "mccp_valid_scores = model_mccp.evaluate(valid_dataset1, metrics, transformers1)\n",
        "\n",
        "print(\"Multitask Classifier + Circular Fingerprints: \")\n",
        "print('Train scores: ', mccp_train_scores)\n",
        "print('Test scores: ', mccp_test_scores)\n",
        "print('Validation scores: ', mccp_valid_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJgmyKzo3Dcu",
        "outputId": "12c1256c-cda2-4e9f-eecd-54332d1a9daa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fit time for this cell at 50 epochs:  9.887231710000378\n",
            "Timestamp: 2023-03-23 15:50:35\n",
            "Multitask Classifier + Circular Fingerprints: \n",
            "Train scores:  {'mean-roc_auc_score': 0.9881476687901034, 'mean-balanced_accuracy_score': 0.9598760263126862}\n",
            "Test scores:  {'mean-roc_auc_score': 0.6700880389242442, 'mean-balanced_accuracy_score': 0.6063133430911144}\n",
            "Validation scores:  {'mean-roc_auc_score': 0.6823168793080989, 'mean-balanced_accuracy_score': 0.6030033464587995}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reload saved model trained on 03/23"
      ],
      "metadata": {
        "id": "NOPjyBKKH99Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mccp_reload = dc.models.MultitaskClassifier(n_tasks=12, n_features=1024, layer_sizes=[1000, 1000], learning_rate = 0.0005, dropouts=0.5, random_state=2, model_dir='./someDirectory/someFolder') \n",
        "mccp_reload.restore()\n",
        "\n",
        "#Scores are identical after running multiple times with the same reloaded model\n",
        "mccp_train_scores = mccp_reload.evaluate(train_dataset1, metrics, transformers1)\n",
        "mccp_test_scores = mccp_reload.evaluate(test_dataset1, metrics, transformers1)\n",
        "print('Reloaded Train scores: ', mccp_train_scores)\n",
        "print('Reloaded Test scores: ', mccp_test_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3A7qjmr1rKi-",
        "outputId": "3650c822-685e-4997-8e3c-d97b222d4af6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reloaded Train scores:  {'mean-roc_auc_score': 0.9881476687901034, 'mean-balanced_accuracy_score': 0.9598760263126862}\n",
            "Reloaded Test scores:  {'mean-roc_auc_score': 0.6700880389242442, 'mean-balanced_accuracy_score': 0.6063133430911144}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model #2: Multitask Classifier using RDKitDescriptors  "
      ],
      "metadata": {
        "id": "qFUSqPUukeNo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load, featurize and transform data: Break SMILES to RDKit descriptors"
      ],
      "metadata": {
        "id": "5o4vCQWjNAc1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#RDKitDescriptors computing WITHOUT normalization took 1m ; WITH normalization takes 4x as long \n",
        "tox21_tasks2, tox21_datasets2, transformers2 = dc.molnet.load_tox21(featurizer=dc.feat.RDKitDescriptors(is_normalized=False))\n",
        "\n",
        "train_dataset2, valid_dataset2, test_dataset2 = tox21_datasets2\n",
        "train_dataset2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opXpwKgZhMr1",
        "outputId": "11312307-50c8-4111-ffcb-12cbd6df04b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[22:23:20] WARNING: not removing hydrogen atom without neighbors\n",
            "[22:23:20] WARNING: not removing hydrogen atom without neighbors\n",
            "[22:23:20] WARNING: not removing hydrogen atom without neighbors\n",
            "[22:24:45] WARNING: not removing hydrogen atom without neighbors\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<DiskDataset X.shape: (6264, 208), y.shape: (6264, 12), w.shape: (6264, 12), task_names: ['NR-AR' 'NR-AR-LBD' 'NR-AhR' ... 'SR-HSE' 'SR-MMP' 'SR-p53']>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fix NaNs and Infinities in the featurized data"
      ],
      "metadata": {
        "id": "HpKCw8UoJftg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fix NaNs and Infinities - these should've been fixed by the featurizer but seems to have problems via DeepChem \n",
        "#We will define a function to fix them manually\n",
        "\n",
        "def fill_infs_nans (split_dataset):\n",
        "  df = pd.DataFrame(split_dataset)\n",
        "  df = df.replace([np.inf, -np.inf], np.nan)\n",
        "  df = df.fillna(0)\n",
        "  return df\n",
        "print(np.isnan(train_dataset2.X).any())\n",
        "print(~np.isfinite(train_dataset2.X).any())\n",
        "\n",
        "#Need to fix NaN in trai, test and validation sets\n",
        "train_dataset2_f = dc.data.DiskDataset.from_numpy(fill_infs_nans(train_dataset2.X),train_dataset2.y, train_dataset2.w, tasks=tox21_tasks2)\n",
        "test_dataset2_f = dc.data.DiskDataset.from_numpy(fill_infs_nans(test_dataset2.X),test_dataset2.y, test_dataset2.w, tasks=tox21_tasks2)\n",
        "valid_dataset2_f = dc.data.DiskDataset.from_numpy(fill_infs_nans(valid_dataset2.X), valid_dataset2.y, valid_dataset2.w, tasks=tox21_tasks2)\n",
        "#No more NAN in training data\n",
        "print(np.isnan(train_dataset2_f.X).any())\n",
        "print(~np.isfinite(train_dataset2_f.X).any())"
      ],
      "metadata": {
        "id": "nsWAUtoBLmqO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae3208ee-5e92-4861-d02e-dc53567b8f3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n",
            "False\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Grid Search for Model #2: Multitask classifer via RDKit Descriptors"
      ],
      "metadata": {
        "id": "WsxoYzqPCT_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#took 40s\n",
        "def model_builder(**model_params):\n",
        "  dropout = model_params['dropout']\n",
        "  layer_sizes = model_params['layer_sizes']\n",
        "  learning_rate = model_params['learning_rate']\n",
        "  model = dc.models.MultitaskClassifier(n_tasks=12, n_features=208, layer_sizes=layer_sizes, learning_rate=learning_rate, dropouts=dropout, random_state=2) \n",
        "  return model\n",
        "\n",
        "params = {\n",
        "    'dropout':[0, 0.2, 0.3, 0.5],\n",
        "    'layer_sizes':[[500],[1000],[1000, 1000]],\n",
        "    'learning_rate':[0.0005, 0.001, 0.005]\n",
        "    }\n",
        "\n",
        "optimizer = dc.hyper.GridHyperparamOpt(model_builder)\n",
        "metric = dc.metrics.Metric(dc.metrics.roc_auc_score, np.mean, mode=\"classification\")\n",
        "\n",
        "best_model_mcrd, best_hyperparams_mcrd, all_results_mcrd = optimizer.hyperparam_search(params, train_dataset2_f, test_dataset2_f, metric)\n",
        "\n",
        "print(\"Timestamp:\", date_now, datetime.now(pytz.timezone('America/Vancouver')).strftime(\"%H:%M:%S\"))\n",
        "print(best_hyperparams_mcrd)\n",
        "all_results_mcrd"
      ],
      "metadata": {
        "id": "Bj0nxnzFI-HW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "511d5cbf-0b66-43e6-f4ee-1b247cf61c15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timestamp: 2023-03-23 15:57:12\n",
            "{'dropout': 0.2, 'layer_sizes': [1000, 1000], 'learning_rate': 0.0005}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'_dropout_0_layer_sizes[500]_learning_rate_0.000500': 0.6997384659569866,\n",
              " '_dropout_0_layer_sizes[500]_learning_rate_0.001000': 0.6932999895926075,\n",
              " '_dropout_0_layer_sizes[500]_learning_rate_0.005000': 0.6882564890518176,\n",
              " '_dropout_0_layer_sizes[1000]_learning_rate_0.000500': 0.6877138438049598,\n",
              " '_dropout_0_layer_sizes[1000]_learning_rate_0.001000': 0.6994893793263107,\n",
              " '_dropout_0_layer_sizes[1000]_learning_rate_0.005000': 0.6797793315545344,\n",
              " '_dropout_0_layer_sizes[1000, 1000]_learning_rate_0.000500': 0.7042357516938753,\n",
              " '_dropout_0_layer_sizes[1000, 1000]_learning_rate_0.001000': 0.7093458811796768,\n",
              " '_dropout_0_layer_sizes[1000, 1000]_learning_rate_0.005000': 0.6807536166890961,\n",
              " '_dropout_0.200000_layer_sizes[500]_learning_rate_0.000500': 0.7093130421469976,\n",
              " '_dropout_0.200000_layer_sizes[500]_learning_rate_0.001000': 0.7049693578767614,\n",
              " '_dropout_0.200000_layer_sizes[500]_learning_rate_0.005000': 0.6625341000376629,\n",
              " '_dropout_0.200000_layer_sizes[1000]_learning_rate_0.000500': 0.6991674867012349,\n",
              " '_dropout_0.200000_layer_sizes[1000]_learning_rate_0.001000': 0.6904111954851841,\n",
              " '_dropout_0.200000_layer_sizes[1000]_learning_rate_0.005000': 0.679681064489334,\n",
              " '_dropout_0.200000_layer_sizes[1000, 1000]_learning_rate_0.000500': 0.7188947863452544,\n",
              " '_dropout_0.200000_layer_sizes[1000, 1000]_learning_rate_0.001000': 0.7129928582001809,\n",
              " '_dropout_0.200000_layer_sizes[1000, 1000]_learning_rate_0.005000': 0.6835611540228572,\n",
              " '_dropout_0.300000_layer_sizes[500]_learning_rate_0.000500': 0.6871739849880648,\n",
              " '_dropout_0.300000_layer_sizes[500]_learning_rate_0.001000': 0.6920908709430312,\n",
              " '_dropout_0.300000_layer_sizes[500]_learning_rate_0.005000': 0.6526799690275473,\n",
              " '_dropout_0.300000_layer_sizes[1000]_learning_rate_0.000500': 0.7069009727741745,\n",
              " '_dropout_0.300000_layer_sizes[1000]_learning_rate_0.001000': 0.7043533271286289,\n",
              " '_dropout_0.300000_layer_sizes[1000]_learning_rate_0.005000': 0.6699766420826587,\n",
              " '_dropout_0.300000_layer_sizes[1000, 1000]_learning_rate_0.000500': 0.7069828759467532,\n",
              " '_dropout_0.300000_layer_sizes[1000, 1000]_learning_rate_0.001000': 0.6984228138014948,\n",
              " '_dropout_0.300000_layer_sizes[1000, 1000]_learning_rate_0.005000': 0.6756082349025924,\n",
              " '_dropout_0.500000_layer_sizes[500]_learning_rate_0.000500': 0.6843875205245099,\n",
              " '_dropout_0.500000_layer_sizes[500]_learning_rate_0.001000': 0.6922292339962507,\n",
              " '_dropout_0.500000_layer_sizes[500]_learning_rate_0.005000': 0.6420429336420975,\n",
              " '_dropout_0.500000_layer_sizes[1000]_learning_rate_0.000500': 0.6839742026487413,\n",
              " '_dropout_0.500000_layer_sizes[1000]_learning_rate_0.001000': 0.6897786416516251,\n",
              " '_dropout_0.500000_layer_sizes[1000]_learning_rate_0.005000': 0.6444605408562686,\n",
              " '_dropout_0.500000_layer_sizes[1000, 1000]_learning_rate_0.000500': 0.707524075633093,\n",
              " '_dropout_0.500000_layer_sizes[1000, 1000]_learning_rate_0.001000': 0.6930768890280904,\n",
              " '_dropout_0.500000_layer_sizes[1000, 1000]_learning_rate_0.005000': 0.579267722126002}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Best MultitaskClassifier + RDD model: save model on G:drive"
      ],
      "metadata": {
        "id": "NfAVd9AKHpfu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = timeit.default_timer()\n",
        "\n",
        "model_mcrd = dc.models.MultitaskClassifier(n_tasks=12, n_features=208, layer_sizes=[1000, 1000], learning_rate = 0.0005, dropouts=0.2, random_state=2, model_dir='./someDirectory/someFolder') \n",
        "model_mcrd.fit(train_dataset2_f, nb_epoch=50)\n",
        "\n",
        "elapsed = timeit.default_timer() - start_time\n",
        "print(\"Fit time for this cell at 50 epochs: \", elapsed)\n",
        "print(\"Timestamp:\", date_now, datetime.now(pytz.timezone('America/Vancouver')).strftime(\"%H:%M:%S\"))\n",
        "\n",
        "metrics = [dc.metrics.Metric(dc.metrics.roc_auc_score, np.mean, mode=\"classification\"),dc.metrics.Metric(dc.metrics.balanced_accuracy_score, np.mean, mode=\"classification\")]\n",
        "\n",
        "train_scores_mcrd = model_mcrd.evaluate(train_dataset2_f, metrics, transformers2)\n",
        "test_scores_mcrd = model_mcrd.evaluate(test_dataset2_f, metrics, transformers2)\n",
        "valid_scores_mcrd = model_mcrd.evaluate(valid_dataset2_f, metrics, transformers2)\n",
        "\n",
        "print(\"Multitask Classifier + RDKit Descriptors:\")\n",
        "print('Train auc: ', train_scores_mcrd)\n",
        "print('Test auc: ', test_scores_mcrd)\n",
        "print('Validation auc: ', valid_scores_mcrd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDxD12nCCTma",
        "outputId": "7c786d84-8e1a-4527-b2df-72aa78927eab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fit time for this cell at 50 epochs:  7.329311847999634\n",
            "Timestamp: 2023-03-23 15:59:16\n",
            "Multitask Classifier + RDKit Descriptors:\n",
            "Train auc:  {'mean-roc_auc_score': 0.9567101431839092, 'mean-balanced_accuracy_score': 0.8985073352225194}\n",
            "Test auc:  {'mean-roc_auc_score': 0.7176311177288298, 'mean-balanced_accuracy_score': 0.6479214345498941}\n",
            "Validation auc:  {'mean-roc_auc_score': 0.7310291550379353, 'mean-balanced_accuracy_score': 0.6632821535341712}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model #3: GraphConv Model with ConvMolFeaturizer"
      ],
      "metadata": {
        "id": "Fed8fAwZKKqX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "References: \n",
        "\n",
        "https://deepchem.readthedocs.io/en/latest/get_started/examples.html\n",
        "https://notebook.community/miaecle/deepchem/examples/notebooks/graph_convolutional_networks_for_tox21_on_colab"
      ],
      "metadata": {
        "id": "jeRTPKA_K3wi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load, featurize and transform data: Break SMILES to ConvMol features"
      ],
      "metadata": {
        "id": "OLJ1HOaCNHVp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tox21_tasks3, tox21_datasets3, transformers3 = dc.molnet.load_tox21(featurizer=dc.feat.ConvMolFeaturizer())\n",
        "train_dataset3, valid_dataset3, test_dataset3 = tox21_datasets3\n",
        "train_dataset3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmkGL_8ZLl-G",
        "outputId": "8450be6a-0d68-425e-c1b9-6ec00c6f42f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[19:30:30] WARNING: not removing hydrogen atom without neighbors\n",
            "[19:30:51] WARNING: not removing hydrogen atom without neighbors\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<DiskDataset X.shape: (6264,), y.shape: (6264, 12), w.shape: (6264, 12), task_names: ['NR-AR' 'NR-AR-LBD' 'NR-AhR' ... 'SR-HSE' 'SR-MMP' 'SR-p53']>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Grid Search for Model #3: GraphConv Model"
      ],
      "metadata": {
        "id": "h9zE_W4QKFb-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#took 11 min\n",
        "def model_builder(**model_params):\n",
        "  dropout = model_params['dropout']\n",
        "  batch_size = model_params['batch_size']\n",
        "  learning_rate = model_params['learning_rate']\n",
        "  model = dc.models.GraphConvModel(12, batch_size=batch_size, mode='classification', dropout=dropout, learning_rate = learning_rate, random_state=2)\n",
        "  return model\n",
        "\n",
        "params = {\n",
        "    'dropout':[0,0.2,0.4],\n",
        "    'batch_size':[50,100],\n",
        "    'learning_rate':[0.0005, 0.001]\n",
        "    }\n",
        "optimizer = dc.hyper.GridHyperparamOpt(model_builder)\n",
        "metric = dc.metrics.Metric(dc.metrics.roc_auc_score, np.mean, mode=\"classification\")\n",
        "\n",
        "best_model_gc,best_hyperparams_gc, all_results_gc = optimizer.hyperparam_search(params, train_dataset3, test_dataset3, metric)\n",
        "\n",
        "print(\"Timestamp:\", date_now, datetime.now(pytz.timezone('America/Vancouver')).strftime(\"%H:%M:%S\"))\n",
        "print(best_hyperparams_gc)\n",
        "all_results_gc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpP2SwusKEox",
        "outputId": "f4a8652b-3a03-4f0c-d307-093bf2b4b5f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 25 calls to <function KerasModel._compute_model at 0x7f553def3ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 17 calls to <function KerasModel._compute_model at 0x7f55766290d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timestamp: 2023-03-31 12:43:13\n",
            "{'dropout': 0, 'batch_size': 100, 'learning_rate': 0.001}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'_batch_size_50_dropout_0_learning_rate_0.000500': 0.6945903711014921,\n",
              " '_batch_size_50_dropout_0_learning_rate_0.001000': 0.6790927998136542,\n",
              " '_batch_size_100_dropout_0_learning_rate_0.000500': 0.689944216057357,\n",
              " '_batch_size_100_dropout_0_learning_rate_0.001000': 0.6948445331093054,\n",
              " '_batch_size_50_dropout_0.200000_learning_rate_0.000500': 0.6608902301534528,\n",
              " '_batch_size_50_dropout_0.200000_learning_rate_0.001000': 0.6902826635842213,\n",
              " '_batch_size_100_dropout_0.200000_learning_rate_0.000500': 0.6883215288618537,\n",
              " '_batch_size_100_dropout_0.200000_learning_rate_0.001000': 0.6838534078060906,\n",
              " '_batch_size_50_dropout_0.400000_learning_rate_0.000500': 0.6715296263469268,\n",
              " '_batch_size_50_dropout_0.400000_learning_rate_0.001000': 0.6692836891998519,\n",
              " '_batch_size_100_dropout_0.400000_learning_rate_0.000500': 0.6641911681453104,\n",
              " '_batch_size_100_dropout_0.400000_learning_rate_0.001000': 0.6678657355269183}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Best GraphConv Model: save model on G:drive"
      ],
      "metadata": {
        "id": "Jn6yfveOY7MB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = timeit.default_timer()\n",
        "\n",
        "model_gc = dc.models.GraphConvModel(12, mode='classification', dropout=0, batch_size=50, number_atom_features = 75, learning_rate = 0.001, random_state=2,\n",
        "                                    model_dir=\"./someDirectory/someFolder\")\n",
        "model_gc.fit(train_dataset3, nb_epoch=50)\n",
        "\n",
        "elapsed = timeit.default_timer() - start_time\n",
        "print(\"Fit time for this fitting at 50 epochs: \", elapsed)\n",
        "print(\"Timestamp:\", date_now, datetime.now(pytz.timezone('America/Vancouver')).strftime(\"%H:%M:%S\"))\n",
        "\n",
        "metrics = [dc.metrics.Metric(dc.metrics.roc_auc_score, np.mean, mode=\"classification\"),dc.metrics.Metric(dc.metrics.balanced_accuracy_score, np.mean, mode=\"classification\")]\n",
        "\n",
        "train_scores_gc = model_gc.evaluate(train_dataset3, metrics, transformers3)\n",
        "test_scores_gc = model_gc.evaluate(test_dataset3, metrics, transformers3)\n",
        "valid_scores_gc = model_gc.evaluate(valid_dataset3, metrics, transformers3)\n",
        "\n",
        "print(\"GraphConv Model\")\n",
        "print('Train auc: ', train_scores_gc)\n",
        "print('Test auc: ', test_scores_gc)\n",
        "print('Validation auc: ', valid_scores_gc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-WnZV17KEsD",
        "outputId": "81363b9b-d938-4a15-fe25-870f79218a3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fit time for this fitting at 50 epochs:  149.998269273\n",
            "Timestamp: 2023-03-23 16:34:47\n",
            "GraphConv Model\n",
            "Train auc:  {'mean-roc_auc_score': 0.9652034019131875, 'mean-balanced_accuracy_score': 0.9108551966954592}\n",
            "Test auc:  {'mean-roc_auc_score': 0.7015209121994253, 'mean-balanced_accuracy_score': 0.6369161772460478}\n",
            "Validation auc:  {'mean-roc_auc_score': 0.7309163160714919, 'mean-balanced_accuracy_score': 0.6461992766856727}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model #4: Graph Convolution Networks (GCN) model with MolGraphConvFeaturizer \n"
      ],
      "metadata": {
        "id": "vOYhyWaPSmNP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Must install the two libraries below for GCN, GAT and ATP to work"
      ],
      "metadata": {
        "id": "IbNS358rMRsc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install  dgl -f https://data.dgl.ai/wheels/cu117/repo.html\n",
        "!pip install dgllife"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6Z8jyIzVybM",
        "outputId": "bcc67645-bb32-4d54-94f3-c0b35a33a7b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.dgl.ai/wheels/cu117/repo.html\n",
            "Collecting dgl\n",
            "  Downloading https://data.dgl.ai/wheels/cu117/dgl-1.0.1%2Bcu117-cp39-cp39-manylinux1_x86_64.whl (266.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.3/266.3 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from dgl) (1.8.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from dgl) (2.27.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.9/dist-packages (from dgl) (1.22.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.9/dist-packages (from dgl) (5.9.4)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.9/dist-packages (from dgl) (3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from dgl) (4.65.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->dgl) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->dgl) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->dgl) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->dgl) (2022.12.7)\n",
            "Installing collected packages: dgl\n",
            "Successfully installed dgl-1.0.1+cu117\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dgllife\n",
            "  Downloading dgllife-0.3.2-py3-none-any.whl (226 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.1/226.1 KB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.9/dist-packages (from dgllife) (2.27.1)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.9/dist-packages (from dgllife) (3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from dgllife) (1.1.1)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.9/dist-packages (from dgllife) (1.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from dgllife) (4.65.0)\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.9/dist-packages (from dgllife) (0.2.7)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from dgllife) (1.8.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from dgllife) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.9/dist-packages (from dgllife) (1.22.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.22.0->dgllife) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.22.0->dgllife) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.22.0->dgllife) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.22.0->dgllife) (2.0.12)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.22.2->dgllife) (3.1.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.9/dist-packages (from hyperopt->dgllife) (0.18.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from hyperopt->dgllife) (1.16.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.9/dist-packages (from hyperopt->dgllife) (2.2.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.9/dist-packages (from hyperopt->dgllife) (0.10.9.7)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->dgllife) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->dgllife) (2.8.2)\n",
            "Installing collected packages: dgllife\n",
            "Successfully installed dgllife-0.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load, featurize and transform data: Break SMILES to MolGraphConv features"
      ],
      "metadata": {
        "id": "RnhMoQqg1tOy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tox21_tasks4, tox21_datasets4, transformers4 = dc.molnet.load_tox21(featurizer=dc.feat.MolGraphConvFeaturizer())\n",
        "train_dataset4, valid_dataset4, test_dataset4 = tox21_datasets4\n",
        "train_dataset4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFZLrSo7OBDL",
        "outputId": "913bc34d-500a-47d3-cb94-a238897bcc84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[23:39:19] WARNING: not removing hydrogen atom without neighbors\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 255, [Hg+2]. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 659, [Ba+2]. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 985, [TlH2+]. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 1423, [Cr+3]. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 1534, [Fe+2]. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 1722, [Co+2]. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 1933, [PbH2+2]. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 2147, [Fe+3]. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 2251, [Cu+2]. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 2760, [Cd+2]. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 2832, [SnH2+2]. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 4024, [Mn+2]. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 4375, [Be+2]. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 4611, [Zn+2]. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 6547, [SbH6+3]. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 6717, [Ni+2]. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
            "/usr/local/lib/python3.9/dist-packages/deepchem/feat/base_classes.py:322: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  return np.asarray(features)\n",
            "[23:40:29] WARNING: not removing hydrogen atom without neighbors\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<DiskDataset X.shape: (6252,), y.shape: (6252, 12), w.shape: (6252, 12), task_names: ['NR-AR' 'NR-AR-LBD' 'NR-AhR' ... 'SR-HSE' 'SR-MMP' 'SR-p53']>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Grid Search for Model #4: GCN"
      ],
      "metadata": {
        "id": "EMmDsmQNV4fg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Took 9 min\n",
        "def model_builder(**model_params):\n",
        "  dropout = model_params['dropout']\n",
        "  batch_size = model_params['batch_size']\n",
        "  learning_rate = model_params['learning_rate']\n",
        "  model = dc.models.GCNModel(len(tox21_tasks4), batch_size=batch_size, mode='classification', learning_rate=learning_rate, dropout=dropout, random_state=2)\n",
        "  return model\n",
        "\n",
        "params = {\n",
        "    'dropout':[0,0.2,0.4],\n",
        "    'batch_size':[50,100],\n",
        "    'learning_rate':[0.0005,0.001]\n",
        "    }\n",
        "\n",
        "optimizer = dc.hyper.GridHyperparamOpt(model_builder)\n",
        "metric = dc.metrics.Metric(dc.metrics.roc_auc_score, np.mean, mode=\"classification\")\n",
        "\n",
        "best_model_gcn, best_hyperparams_gcn, all_results_gcn = optimizer.hyperparam_search(params, train_dataset4, test_dataset4, metric)\n",
        "\n",
        "print(\"Timestamp:\", date_now, datetime.now(pytz.timezone('America/Vancouver')).strftime(\"%H:%M:%S\"))\n",
        "print(best_hyperparams_gcn)\n",
        "all_results_gcn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kevx7RBCV3ah",
        "outputId": "0dcc2eac-ec89-42a7-c035-0bebe54a4dbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n",
            "Timestamp: 2023-03-23 16:50:44\n",
            "{'dropout': 0, 'batch_size': 50, 'learning_rate': 0.0005}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'_batch_size_50_dropout_0_learning_rate_0.000500': 0.7233308807462834,\n",
              " '_batch_size_50_dropout_0_learning_rate_0.001000': 0.7042873395073977,\n",
              " '_batch_size_100_dropout_0_learning_rate_0.000500': 0.7061973078044973,\n",
              " '_batch_size_100_dropout_0_learning_rate_0.001000': 0.7157140032670458,\n",
              " '_batch_size_50_dropout_0.200000_learning_rate_0.000500': 0.7051157402532708,\n",
              " '_batch_size_50_dropout_0.200000_learning_rate_0.001000': 0.7165027600870749,\n",
              " '_batch_size_100_dropout_0.200000_learning_rate_0.000500': 0.7152434398508499,\n",
              " '_batch_size_100_dropout_0.200000_learning_rate_0.001000': 0.7186074615477588,\n",
              " '_batch_size_50_dropout_0.400000_learning_rate_0.000500': 0.6999171607991862,\n",
              " '_batch_size_50_dropout_0.400000_learning_rate_0.001000': 0.7191497254368827,\n",
              " '_batch_size_100_dropout_0.400000_learning_rate_0.000500': 0.7153264986430288,\n",
              " '_batch_size_100_dropout_0.400000_learning_rate_0.001000': 0.7005504675377826}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Best GCN Model: save model on G:drive"
      ],
      "metadata": {
        "id": "hRzrnHev7BGC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### We can write a function to score tuned model and print the scores"
      ],
      "metadata": {
        "id": "vlNOZlGoSEOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Write function to score tuned model and print auc and balanced accuracy scores\n",
        "def score_tox_model(best_model, train, test, valid, transformers):\n",
        "  metrics = [dc.metrics.Metric(dc.metrics.roc_auc_score, np.mean, mode=\"classification\"),\n",
        "             dc.metrics.Metric(dc.metrics.balanced_accuracy_score, np.mean, mode=\"classification\")]\n",
        "  train_scores = best_model.evaluate(train, metrics, transformers)\n",
        "  test_scores = best_model.evaluate(test, metrics, transformers)\n",
        "  valid_scores = best_model.evaluate(valid, metrics, transformers)\n",
        "\n",
        "  print(best_model)\n",
        "  print('Train auc: ', train_scores)\n",
        "  print('Test auc: ', test_scores)\n",
        "  print('Validation auc: ', valid_scores)"
      ],
      "metadata": {
        "id": "GZFfvstk4y8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import timeit\n",
        "start_time = timeit.default_timer()\n",
        "\n",
        "model_gcn = dc.models.GCNModel(12, mode='classification', batch_size=50, dropout=0.0, learning_rate=0.0005, random_state=2, \n",
        "                               model_dir=\"./someDirectory/someFolder\")\n",
        "model_gcn.fit(train_dataset4, nb_epoch=50)\n",
        "\n",
        "elapsed = timeit.default_timer() - start_time\n",
        "print(\"Fit time for this fitting at 50 epochs: \", elapsed)\n",
        "print(\"Timestamp:\", date_now, datetime.now(pytz.timezone('America/Vancouver')).strftime(\"%H:%M:%S\"))\n",
        "\n",
        "print(\"GCN Model\")\n",
        "score_tox_model(model_gcn, train_dataset4, test_dataset4, valid_dataset4, transformers4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aH2Cqs95V3eW",
        "outputId": "e6762e59-9ecc-4ce9-eed6-89e12fa49a52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fit time for this fitting at 50 epochs:  220.50128360099916\n",
            "Timestamp: 2023-03-23 17:11:40\n",
            "GCN Model\n",
            "<deepchem.models.torch_models.gcn.GCNModel object at 0x7f054efa45b0>\n",
            "Train auc:  {'mean-roc_auc_score': 0.9306676538018488, 'mean-balanced_accuracy_score': 0.8587542280628616}\n",
            "Test auc:  {'mean-roc_auc_score': 0.713228243515204, 'mean-balanced_accuracy_score': 0.661032683957013}\n",
            "Validation auc:  {'mean-roc_auc_score': 0.7547775297749807, 'mean-balanced_accuracy_score': 0.6857672018196799}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model #5: Graph Attention Networks (GAT) Model via MolGraphConv features"
      ],
      "metadata": {
        "id": "KtbPMyBRTlSn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Grid Search for Model #5: GAT"
      ],
      "metadata": {
        "id": "2h8AShvcembt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Took 14 min\n",
        "def model_builder(**model_params):\n",
        "  dropout = model_params['dropout']\n",
        "  batch_size = model_params['batch_size']\n",
        "  learning_rate = model_params['learning_rate']\n",
        "  model = dc.models.GATModel(12, batch_size=batch_size, mode='classification', dropout=dropout,learning_rate=learning_rate,random_state=2)\n",
        "  return model\n",
        "\n",
        "params = {\n",
        "    'dropout':[0,0.2,0.4],\n",
        "    'batch_size':[50,100],\n",
        "    'learning_rate':[0.0005,0.001,0.005]\n",
        "    }\n",
        "optimizer = dc.hyper.GridHyperparamOpt(model_builder)\n",
        "metric = dc.metrics.Metric(dc.metrics.roc_auc_score, np.mean, mode=\"classification\")\n",
        "\n",
        "best_model_gat, best_hyperparams_gat, all_results_gat = optimizer.hyperparam_search(params, train_dataset4, test_dataset4, metric)\n",
        "\n",
        "print(\"Timestamp:\", date_now, datetime.now(pytz.timezone('America/Vancouver')).strftime(\"%H:%M:%S\"))\n",
        "print(best_hyperparams_gat)\n",
        "all_results_gat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNuwDFbjeb3I",
        "outputId": "e7534bbe-ebb3-4240-abc6-7bbdeb75a5c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timestamp: 2023-03-23 17:29:39\n",
            "{'dropout': 0, 'batch_size': 50, 'learning_rate': 0.005}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'_batch_size_50_dropout_0_learning_rate_0.000500': 0.7107419870024286,\n",
              " '_batch_size_50_dropout_0_learning_rate_0.001000': 0.6804692779528773,\n",
              " '_batch_size_50_dropout_0_learning_rate_0.005000': 0.7167684702619966,\n",
              " '_batch_size_100_dropout_0_learning_rate_0.000500': 0.7065308800175396,\n",
              " '_batch_size_100_dropout_0_learning_rate_0.001000': 0.6933929052658355,\n",
              " '_batch_size_100_dropout_0_learning_rate_0.005000': 0.6997381982099814,\n",
              " '_batch_size_50_dropout_0.200000_learning_rate_0.000500': 0.679635092141817,\n",
              " '_batch_size_50_dropout_0.200000_learning_rate_0.001000': 0.7003141139655656,\n",
              " '_batch_size_50_dropout_0.200000_learning_rate_0.005000': 0.6874852610768244,\n",
              " '_batch_size_100_dropout_0.200000_learning_rate_0.000500': 0.6841818488148764,\n",
              " '_batch_size_100_dropout_0.200000_learning_rate_0.001000': 0.6917325597275488,\n",
              " '_batch_size_100_dropout_0.200000_learning_rate_0.005000': 0.7027826667406467,\n",
              " '_batch_size_50_dropout_0.400000_learning_rate_0.000500': 0.6806624469662097,\n",
              " '_batch_size_50_dropout_0.400000_learning_rate_0.001000': 0.6868135695413136,\n",
              " '_batch_size_50_dropout_0.400000_learning_rate_0.005000': 0.6842831137052556,\n",
              " '_batch_size_100_dropout_0.400000_learning_rate_0.000500': 0.6614085230316628,\n",
              " '_batch_size_100_dropout_0.400000_learning_rate_0.001000': 0.6794180847135864,\n",
              " '_batch_size_100_dropout_0.400000_learning_rate_0.005000': 0.6777024505109764}"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Best GAT Model: save model on G:drive"
      ],
      "metadata": {
        "id": "dxCI1rIOE8ux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = timeit.default_timer()\n",
        "\n",
        "model_gat = dc.models.GATModel(12, mode='classification', batch_size=50, learning_rate=0.005, dropout=0.0, random_state=2,\n",
        "                               model_dir = \"./someDirectory/someFolder\")\n",
        "model_gat.fit(train_dataset4, nb_epoch=50)\n",
        "\n",
        "elapsed = timeit.default_timer() - start_time\n",
        "print(\"Fit time for this fitting at 50 epochs: \", elapsed)\n",
        "print(\"Timestamp:\", date_now, datetime.now(pytz.timezone('America/Vancouver')).strftime(\"%H:%M:%S\"))\n",
        "\n",
        "print(\"GAT Model: \")\n",
        "score_tox_model(model_gat, train_dataset4, test_dataset4, valid_dataset4, transformers4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RGLqQ-Peb7J",
        "outputId": "c6b37b0a-c4b6-4adc-e668-310cfae80ce2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fit time for this fitting at 50 epochs:  282.15603828299936\n",
            "Timestamp: 2023-03-23 17:42:48\n",
            "GAT Model: \n",
            "<deepchem.models.torch_models.gat.GATModel object at 0x7f04e2272040>\n",
            "Train auc:  {'mean-roc_auc_score': 0.878376491996364, 'mean-balanced_accuracy_score': 0.8042491565662258}\n",
            "Test auc:  {'mean-roc_auc_score': 0.7152939212214829, 'mean-balanced_accuracy_score': 0.652446431314727}\n",
            "Validation auc:  {'mean-roc_auc_score': 0.7553473159156949, 'mean-balanced_accuracy_score': 0.6840669322700438}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model #6: AttentiveFPModel"
      ],
      "metadata": {
        "id": "KYuuVLW0dFyN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load, featurize and transform data: Break SMILES to MolGraphConv features WITH EDGES"
      ],
      "metadata": {
        "id": "qXjJhUviOMfm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Use edges for featurizer, took 1min\n",
        "tox21_tasks4b, tox21_datasets4b, transformers4b = dc.molnet.load_tox21(featurizer=dc.feat.MolGraphConvFeaturizer(use_edges=True))\n",
        "train_dataset4b, valid_dataset4b, test_dataset4b = tox21_datasets4b\n",
        "train_dataset4b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWTa7Y5edM00",
        "outputId": "0952e880-05ef-4d4d-ea11-4475d7a380b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 95, [I-].[K+]. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: tuple index out of range\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 255, [Hg+2]. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 659, [Ba+2]. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 985, [TlH2+]. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 1423, [Cr+3]. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 1534, [Fe+2]. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 1722, [Co+2]. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 1933, [PbH2+2]. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 2147, [Fe+3]. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 2251, [Cu+2]. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 2760, [Cd+2]. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 2832, [SnH2+2]. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 4024, [Mn+2]. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 4375, [Be+2]. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 4611, [Zn+2]. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 5942, [Br-].[Na+]. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: tuple index out of range\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 6477, [Ca+2].[Cl-].[Cl-]. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: tuple index out of range\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 6547, [SbH6+3]. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
            "WARNING:deepchem.feat.base_classes:Failed to featurize datapoint 6717, [Ni+2]. Appending empty array\n",
            "WARNING:deepchem.feat.base_classes:Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
            "/usr/local/lib/python3.9/dist-packages/deepchem/feat/base_classes.py:322: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  return np.asarray(features)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<DiskDataset X.shape: (6249,), y.shape: (6249, 12), w.shape: (6249, 12), task_names: ['NR-AR' 'NR-AR-LBD' 'NR-AhR' ... 'SR-HSE' 'SR-MMP' 'SR-p53']>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Grid Search for Model #6: AFP"
      ],
      "metadata": {
        "id": "5E-B846GmAvt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Took 23 min\n",
        "def model_builder(**model_params):\n",
        "  dropout = model_params['dropout']\n",
        "  batch_size = model_params['batch_size']\n",
        "  learning_rate = model_params['learning_rate']\n",
        "  model = dc.models.AttentiveFPModel(12, batch_size=batch_size,mode='classification',dropout=dropout,learning_rate=learning_rate,random_state=2)\n",
        "  return model\n",
        "\n",
        "params = {\n",
        "    'dropout':[0,0.2,0.4],\n",
        "    'batch_size':[25,50,100],\n",
        "    'learning_rate':[0.0005,0.001]\n",
        "    }\n",
        "optimizer = dc.hyper.GridHyperparamOpt(model_builder)\n",
        "metric = dc.metrics.Metric(dc.metrics.roc_auc_score, np.mean, mode=\"classification\")\n",
        "\n",
        "best_model_afp, best_hyperparams_afp, all_results_afp = optimizer.hyperparam_search(params, train_dataset4b, test_dataset4b, metric)\n",
        "\n",
        "print(\"Timestamp:\", date_now, datetime.now(pytz.timezone('America/Vancouver')).strftime(\"%H:%M:%S\"))\n",
        "print(best_hyperparams_afp)\n",
        "all_results_afp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4s1Q0QF4b8I2",
        "outputId": "cbd89a06-bb73-45cb-e353-4f6514996103"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timestamp: 2023-03-23 18:06:57\n",
            "{'dropout': 0.4, 'batch_size': 100, 'learning_rate': 0.0005}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'_batch_size_25_dropout_0_learning_rate_0.000500': 0.7177609512562583,\n",
              " '_batch_size_25_dropout_0_learning_rate_0.001000': 0.7220399345910384,\n",
              " '_batch_size_50_dropout_0_learning_rate_0.000500': 0.7204011381644152,\n",
              " '_batch_size_50_dropout_0_learning_rate_0.001000': 0.725402344919396,\n",
              " '_batch_size_100_dropout_0_learning_rate_0.000500': 0.7282751662475663,\n",
              " '_batch_size_100_dropout_0_learning_rate_0.001000': 0.7265430474468193,\n",
              " '_batch_size_25_dropout_0.200000_learning_rate_0.000500': 0.7286629298175983,\n",
              " '_batch_size_25_dropout_0.200000_learning_rate_0.001000': 0.7171444043348928,\n",
              " '_batch_size_50_dropout_0.200000_learning_rate_0.000500': 0.7293089917738461,\n",
              " '_batch_size_50_dropout_0.200000_learning_rate_0.001000': 0.7039482860772509,\n",
              " '_batch_size_100_dropout_0.200000_learning_rate_0.000500': 0.728722369409045,\n",
              " '_batch_size_100_dropout_0.200000_learning_rate_0.001000': 0.723364995625765,\n",
              " '_batch_size_25_dropout_0.400000_learning_rate_0.000500': 0.7214136200330667,\n",
              " '_batch_size_25_dropout_0.400000_learning_rate_0.001000': 0.724229646866387,\n",
              " '_batch_size_50_dropout_0.400000_learning_rate_0.000500': 0.7186424378425001,\n",
              " '_batch_size_50_dropout_0.400000_learning_rate_0.001000': 0.7183641440033073,\n",
              " '_batch_size_100_dropout_0.400000_learning_rate_0.000500': 0.7310230664989423,\n",
              " '_batch_size_100_dropout_0.400000_learning_rate_0.001000': 0.7256055369146429}"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Best AttentiveFP Model: saved on G:drive"
      ],
      "metadata": {
        "id": "LfIRYpW-23nd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = timeit.default_timer()\n",
        "\n",
        "model_afp = dc.models.AttentiveFPModel(n_tasks=12, mode='classification', dropout=0.4, batch_size=100, learning_rate=0.0005, random_state=2,\n",
        "                                       model_dir = \"./someDirectory/someFolder\")\n",
        "model_afp.fit(train_dataset4b, nb_epoch=50)\n",
        "\n",
        "elapsed = timeit.default_timer() - start_time\n",
        "print(\"Fit time for this fitting at 50 epochs: \", elapsed)\n",
        "print(\"Timestamp:\", date_now, datetime.now(pytz.timezone('America/Vancouver')).strftime(\"%H:%M:%S\"))\n",
        "\n",
        "print(\"AFP Model: \")\n",
        "score_tox_model(model_afp, train_dataset4b, test_dataset4b, valid_dataset4b, transformers4b)"
      ],
      "metadata": {
        "id": "Pi0iGvOM24MA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d10fac80-4f40-401d-ad58-bba609005052"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fit time for this fitting at 50 epochs:  268.19820892700045\n",
            "Timestamp: 2023-03-23 18:14:09\n",
            "AFP Model: \n",
            "<deepchem.models.torch_models.attentivefp.AttentiveFPModel object at 0x7f04e87ffac0>\n",
            "Train auc:  {'mean-roc_auc_score': 0.9597742738378705, 'mean-balanced_accuracy_score': 0.9132702614288238}\n",
            "Test auc:  {'mean-roc_auc_score': 0.7349533419945021, 'mean-balanced_accuracy_score': 0.6790515926855938}\n",
            "Validation auc:  {'mean-roc_auc_score': 0.7416443872723001, 'mean-balanced_accuracy_score': 0.6925993286369022}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model #7: Weave Model \n"
      ],
      "metadata": {
        "id": "imB3zhHECT1L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load, featurize and transform data using WeaveFeaturizer"
      ],
      "metadata": {
        "id": "ICMnoNEFPMQD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Took 1 min\n",
        "tox21_tasks5, tox21_datasets5, transformers5 = dc.molnet.load_tox21(featurizer=dc.feat.WeaveFeaturizer())\n",
        "train_dataset5, valid_dataset5, test_dataset5 = tox21_datasets5\n",
        "train_dataset5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eN83cJwyOjQ",
        "outputId": "133098ec-2154-40f8-cd9f-586ff1585580"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[06:08:55] WARNING: not removing hydrogen atom without neighbors\n",
            "[06:10:10] WARNING: not removing hydrogen atom without neighbors\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<DiskDataset X.shape: (6264,), y.shape: (6264, 12), w.shape: (6264, 12), task_names: ['NR-AR' 'NR-AR-LBD' 'NR-AhR' ... 'SR-HSE' 'SR-MMP' 'SR-p53']>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Note: we have to set batch_normalize_kwargs={'trainable': False}, else grid search would return NaNs "
      ],
      "metadata": {
        "id": "DsDZAGeuPIo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#29 min\n",
        "def model_builder(**model_params):\n",
        "  dropout = model_params['dropout']\n",
        "  batch_size = model_params['batch_size']\n",
        "  learning_rate = model_params['learning_rate']\n",
        "  model = dc.models.WeaveModel(12, mode='classification',\n",
        "                               batch_normalize_kwargs={'trainable': False}, batch_size=batch_size,\n",
        "                               dropout=dropout,learning_rate=learning_rate,random_state=2)\n",
        "  return model\n",
        "\n",
        "params = {\n",
        "    'dropout':[0,0.2],\n",
        "    'batch_size':[50,100],\n",
        "    'learning_rate':[0.0005,0.001]\n",
        "    }\n",
        "optimizer = dc.hyper.GridHyperparamOpt(model_builder)\n",
        "metric = dc.metrics.Metric(dc.metrics.roc_auc_score, np.mean, mode=\"classification\")\n",
        "\n",
        "best_model_weave, best_hyperparams_weave, all_results_weave = optimizer.hyperparam_search(params, train_dataset5, test_dataset5, metric)\n",
        "\n",
        "print(\"Timestamp:\", date_now, datetime.now(pytz.timezone('America/Vancouver')).strftime(\"%H:%M:%S\"))\n",
        "print(best_hyperparams_weave)\n",
        "all_results_weave"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "970005de-5f78-4afc-e8ce-72ef50837b26",
        "id": "zXb2qjMmRVgA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer TruncatedNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
            "  warnings.warn(\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['weave_layer_7/kernel:0', 'weave_layer_7/Variable:0', 'weave_layer_7/kernel:0', 'weave_layer_7/Variable:0', 'weave_layer_7/kernel:0', 'weave_layer_7/Variable:0', 'weave_layer_7/batch_normalization_3/gamma:0', 'weave_layer_7/batch_normalization_3/beta:0', 'weave_layer_7/batch_normalization_4/gamma:0', 'weave_layer_7/batch_normalization_4/beta:0', 'weave_layer_7/batch_normalization_5/gamma:0', 'weave_layer_7/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['weave_layer_7/kernel:0', 'weave_layer_7/Variable:0', 'weave_layer_7/kernel:0', 'weave_layer_7/Variable:0', 'weave_layer_7/kernel:0', 'weave_layer_7/Variable:0', 'weave_layer_7/batch_normalization_3/gamma:0', 'weave_layer_7/batch_normalization_3/beta:0', 'weave_layer_7/batch_normalization_4/gamma:0', 'weave_layer_7/batch_normalization_4/beta:0', 'weave_layer_7/batch_normalization_5/gamma:0', 'weave_layer_7/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['weave_layer_7/kernel:0', 'weave_layer_7/Variable:0', 'weave_layer_7/kernel:0', 'weave_layer_7/Variable:0', 'weave_layer_7/kernel:0', 'weave_layer_7/Variable:0', 'weave_layer_7/batch_normalization_3/gamma:0', 'weave_layer_7/batch_normalization_3/beta:0', 'weave_layer_7/batch_normalization_4/gamma:0', 'weave_layer_7/batch_normalization_4/beta:0', 'weave_layer_7/batch_normalization_5/gamma:0', 'weave_layer_7/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['weave_layer_7/kernel:0', 'weave_layer_7/Variable:0', 'weave_layer_7/kernel:0', 'weave_layer_7/Variable:0', 'weave_layer_7/kernel:0', 'weave_layer_7/Variable:0', 'weave_layer_7/batch_normalization_3/gamma:0', 'weave_layer_7/batch_normalization_3/beta:0', 'weave_layer_7/batch_normalization_4/gamma:0', 'weave_layer_7/batch_normalization_4/beta:0', 'weave_layer_7/batch_normalization_5/gamma:0', 'weave_layer_7/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['weave_layer_7/kernel:0', 'weave_layer_7/Variable:0', 'weave_layer_7/kernel:0', 'weave_layer_7/Variable:0', 'weave_layer_7/kernel:0', 'weave_layer_7/Variable:0', 'weave_layer_7/batch_normalization_3/gamma:0', 'weave_layer_7/batch_normalization_3/beta:0', 'weave_layer_7/batch_normalization_4/gamma:0', 'weave_layer_7/batch_normalization_4/beta:0', 'weave_layer_7/batch_normalization_5/gamma:0', 'weave_layer_7/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['weave_layer_7/kernel:0', 'weave_layer_7/Variable:0', 'weave_layer_7/kernel:0', 'weave_layer_7/Variable:0', 'weave_layer_7/kernel:0', 'weave_layer_7/Variable:0', 'weave_layer_7/batch_normalization_3/gamma:0', 'weave_layer_7/batch_normalization_3/beta:0', 'weave_layer_7/batch_normalization_4/gamma:0', 'weave_layer_7/batch_normalization_4/beta:0', 'weave_layer_7/batch_normalization_5/gamma:0', 'weave_layer_7/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer TruncatedNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
            "  warnings.warn(\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['weave_layer_9/kernel:0', 'weave_layer_9/Variable:0', 'weave_layer_9/kernel:0', 'weave_layer_9/Variable:0', 'weave_layer_9/kernel:0', 'weave_layer_9/Variable:0', 'weave_layer_9/batch_normalization_3/gamma:0', 'weave_layer_9/batch_normalization_3/beta:0', 'weave_layer_9/batch_normalization_4/gamma:0', 'weave_layer_9/batch_normalization_4/beta:0', 'weave_layer_9/batch_normalization_5/gamma:0', 'weave_layer_9/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['weave_layer_9/kernel:0', 'weave_layer_9/Variable:0', 'weave_layer_9/kernel:0', 'weave_layer_9/Variable:0', 'weave_layer_9/kernel:0', 'weave_layer_9/Variable:0', 'weave_layer_9/batch_normalization_3/gamma:0', 'weave_layer_9/batch_normalization_3/beta:0', 'weave_layer_9/batch_normalization_4/gamma:0', 'weave_layer_9/batch_normalization_4/beta:0', 'weave_layer_9/batch_normalization_5/gamma:0', 'weave_layer_9/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['weave_layer_9/kernel:0', 'weave_layer_9/Variable:0', 'weave_layer_9/kernel:0', 'weave_layer_9/Variable:0', 'weave_layer_9/kernel:0', 'weave_layer_9/Variable:0', 'weave_layer_9/batch_normalization_3/gamma:0', 'weave_layer_9/batch_normalization_3/beta:0', 'weave_layer_9/batch_normalization_4/gamma:0', 'weave_layer_9/batch_normalization_4/beta:0', 'weave_layer_9/batch_normalization_5/gamma:0', 'weave_layer_9/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['weave_layer_9/kernel:0', 'weave_layer_9/Variable:0', 'weave_layer_9/kernel:0', 'weave_layer_9/Variable:0', 'weave_layer_9/kernel:0', 'weave_layer_9/Variable:0', 'weave_layer_9/batch_normalization_3/gamma:0', 'weave_layer_9/batch_normalization_3/beta:0', 'weave_layer_9/batch_normalization_4/gamma:0', 'weave_layer_9/batch_normalization_4/beta:0', 'weave_layer_9/batch_normalization_5/gamma:0', 'weave_layer_9/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['weave_layer_9/kernel:0', 'weave_layer_9/Variable:0', 'weave_layer_9/kernel:0', 'weave_layer_9/Variable:0', 'weave_layer_9/kernel:0', 'weave_layer_9/Variable:0', 'weave_layer_9/batch_normalization_3/gamma:0', 'weave_layer_9/batch_normalization_3/beta:0', 'weave_layer_9/batch_normalization_4/gamma:0', 'weave_layer_9/batch_normalization_4/beta:0', 'weave_layer_9/batch_normalization_5/gamma:0', 'weave_layer_9/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['weave_layer_9/kernel:0', 'weave_layer_9/Variable:0', 'weave_layer_9/kernel:0', 'weave_layer_9/Variable:0', 'weave_layer_9/kernel:0', 'weave_layer_9/Variable:0', 'weave_layer_9/batch_normalization_3/gamma:0', 'weave_layer_9/batch_normalization_3/beta:0', 'weave_layer_9/batch_normalization_4/gamma:0', 'weave_layer_9/batch_normalization_4/beta:0', 'weave_layer_9/batch_normalization_5/gamma:0', 'weave_layer_9/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer TruncatedNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
            "  warnings.warn(\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['weave_layer_11/kernel:0', 'weave_layer_11/Variable:0', 'weave_layer_11/kernel:0', 'weave_layer_11/Variable:0', 'weave_layer_11/kernel:0', 'weave_layer_11/Variable:0', 'weave_layer_11/batch_normalization_3/gamma:0', 'weave_layer_11/batch_normalization_3/beta:0', 'weave_layer_11/batch_normalization_4/gamma:0', 'weave_layer_11/batch_normalization_4/beta:0', 'weave_layer_11/batch_normalization_5/gamma:0', 'weave_layer_11/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['weave_layer_11/kernel:0', 'weave_layer_11/Variable:0', 'weave_layer_11/kernel:0', 'weave_layer_11/Variable:0', 'weave_layer_11/kernel:0', 'weave_layer_11/Variable:0', 'weave_layer_11/batch_normalization_3/gamma:0', 'weave_layer_11/batch_normalization_3/beta:0', 'weave_layer_11/batch_normalization_4/gamma:0', 'weave_layer_11/batch_normalization_4/beta:0', 'weave_layer_11/batch_normalization_5/gamma:0', 'weave_layer_11/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['weave_layer_11/kernel:0', 'weave_layer_11/Variable:0', 'weave_layer_11/kernel:0', 'weave_layer_11/Variable:0', 'weave_layer_11/kernel:0', 'weave_layer_11/Variable:0', 'weave_layer_11/batch_normalization_3/gamma:0', 'weave_layer_11/batch_normalization_3/beta:0', 'weave_layer_11/batch_normalization_4/gamma:0', 'weave_layer_11/batch_normalization_4/beta:0', 'weave_layer_11/batch_normalization_5/gamma:0', 'weave_layer_11/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['weave_layer_11/kernel:0', 'weave_layer_11/Variable:0', 'weave_layer_11/kernel:0', 'weave_layer_11/Variable:0', 'weave_layer_11/kernel:0', 'weave_layer_11/Variable:0', 'weave_layer_11/batch_normalization_3/gamma:0', 'weave_layer_11/batch_normalization_3/beta:0', 'weave_layer_11/batch_normalization_4/gamma:0', 'weave_layer_11/batch_normalization_4/beta:0', 'weave_layer_11/batch_normalization_5/gamma:0', 'weave_layer_11/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['weave_layer_11/kernel:0', 'weave_layer_11/Variable:0', 'weave_layer_11/kernel:0', 'weave_layer_11/Variable:0', 'weave_layer_11/kernel:0', 'weave_layer_11/Variable:0', 'weave_layer_11/batch_normalization_3/gamma:0', 'weave_layer_11/batch_normalization_3/beta:0', 'weave_layer_11/batch_normalization_4/gamma:0', 'weave_layer_11/batch_normalization_4/beta:0', 'weave_layer_11/batch_normalization_5/gamma:0', 'weave_layer_11/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['weave_layer_11/kernel:0', 'weave_layer_11/Variable:0', 'weave_layer_11/kernel:0', 'weave_layer_11/Variable:0', 'weave_layer_11/kernel:0', 'weave_layer_11/Variable:0', 'weave_layer_11/batch_normalization_3/gamma:0', 'weave_layer_11/batch_normalization_3/beta:0', 'weave_layer_11/batch_normalization_4/gamma:0', 'weave_layer_11/batch_normalization_4/beta:0', 'weave_layer_11/batch_normalization_5/gamma:0', 'weave_layer_11/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer TruncatedNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
            "  warnings.warn(\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['weave_layer_13/kernel:0', 'weave_layer_13/Variable:0', 'weave_layer_13/kernel:0', 'weave_layer_13/Variable:0', 'weave_layer_13/kernel:0', 'weave_layer_13/Variable:0', 'weave_layer_13/batch_normalization_3/gamma:0', 'weave_layer_13/batch_normalization_3/beta:0', 'weave_layer_13/batch_normalization_4/gamma:0', 'weave_layer_13/batch_normalization_4/beta:0', 'weave_layer_13/batch_normalization_5/gamma:0', 'weave_layer_13/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['weave_layer_13/kernel:0', 'weave_layer_13/Variable:0', 'weave_layer_13/kernel:0', 'weave_layer_13/Variable:0', 'weave_layer_13/kernel:0', 'weave_layer_13/Variable:0', 'weave_layer_13/batch_normalization_3/gamma:0', 'weave_layer_13/batch_normalization_3/beta:0', 'weave_layer_13/batch_normalization_4/gamma:0', 'weave_layer_13/batch_normalization_4/beta:0', 'weave_layer_13/batch_normalization_5/gamma:0', 'weave_layer_13/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['weave_layer_13/kernel:0', 'weave_layer_13/Variable:0', 'weave_layer_13/kernel:0', 'weave_layer_13/Variable:0', 'weave_layer_13/kernel:0', 'weave_layer_13/Variable:0', 'weave_layer_13/batch_normalization_3/gamma:0', 'weave_layer_13/batch_normalization_3/beta:0', 'weave_layer_13/batch_normalization_4/gamma:0', 'weave_layer_13/batch_normalization_4/beta:0', 'weave_layer_13/batch_normalization_5/gamma:0', 'weave_layer_13/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['weave_layer_13/kernel:0', 'weave_layer_13/Variable:0', 'weave_layer_13/kernel:0', 'weave_layer_13/Variable:0', 'weave_layer_13/kernel:0', 'weave_layer_13/Variable:0', 'weave_layer_13/batch_normalization_3/gamma:0', 'weave_layer_13/batch_normalization_3/beta:0', 'weave_layer_13/batch_normalization_4/gamma:0', 'weave_layer_13/batch_normalization_4/beta:0', 'weave_layer_13/batch_normalization_5/gamma:0', 'weave_layer_13/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['weave_layer_13/kernel:0', 'weave_layer_13/Variable:0', 'weave_layer_13/kernel:0', 'weave_layer_13/Variable:0', 'weave_layer_13/kernel:0', 'weave_layer_13/Variable:0', 'weave_layer_13/batch_normalization_3/gamma:0', 'weave_layer_13/batch_normalization_3/beta:0', 'weave_layer_13/batch_normalization_4/gamma:0', 'weave_layer_13/batch_normalization_4/beta:0', 'weave_layer_13/batch_normalization_5/gamma:0', 'weave_layer_13/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['weave_layer_13/kernel:0', 'weave_layer_13/Variable:0', 'weave_layer_13/kernel:0', 'weave_layer_13/Variable:0', 'weave_layer_13/kernel:0', 'weave_layer_13/Variable:0', 'weave_layer_13/batch_normalization_3/gamma:0', 'weave_layer_13/batch_normalization_3/beta:0', 'weave_layer_13/batch_normalization_4/gamma:0', 'weave_layer_13/batch_normalization_4/beta:0', 'weave_layer_13/batch_normalization_5/gamma:0', 'weave_layer_13/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:5 out of the last 25 calls to <function KerasModel._compute_model at 0x7f3b4507c430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer TruncatedNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
            "  warnings.warn(\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['weave_layer_15/kernel:0', 'weave_layer_15/Variable:0', 'weave_layer_15/kernel:0', 'weave_layer_15/Variable:0', 'weave_layer_15/kernel:0', 'weave_layer_15/Variable:0', 'weave_layer_15/batch_normalization_3/gamma:0', 'weave_layer_15/batch_normalization_3/beta:0', 'weave_layer_15/batch_normalization_4/gamma:0', 'weave_layer_15/batch_normalization_4/beta:0', 'weave_layer_15/batch_normalization_5/gamma:0', 'weave_layer_15/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['weave_layer_15/kernel:0', 'weave_layer_15/Variable:0', 'weave_layer_15/kernel:0', 'weave_layer_15/Variable:0', 'weave_layer_15/kernel:0', 'weave_layer_15/Variable:0', 'weave_layer_15/batch_normalization_3/gamma:0', 'weave_layer_15/batch_normalization_3/beta:0', 'weave_layer_15/batch_normalization_4/gamma:0', 'weave_layer_15/batch_normalization_4/beta:0', 'weave_layer_15/batch_normalization_5/gamma:0', 'weave_layer_15/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['weave_layer_15/kernel:0', 'weave_layer_15/Variable:0', 'weave_layer_15/kernel:0', 'weave_layer_15/Variable:0', 'weave_layer_15/kernel:0', 'weave_layer_15/Variable:0', 'weave_layer_15/batch_normalization_3/gamma:0', 'weave_layer_15/batch_normalization_3/beta:0', 'weave_layer_15/batch_normalization_4/gamma:0', 'weave_layer_15/batch_normalization_4/beta:0', 'weave_layer_15/batch_normalization_5/gamma:0', 'weave_layer_15/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['weave_layer_15/kernel:0', 'weave_layer_15/Variable:0', 'weave_layer_15/kernel:0', 'weave_layer_15/Variable:0', 'weave_layer_15/kernel:0', 'weave_layer_15/Variable:0', 'weave_layer_15/batch_normalization_3/gamma:0', 'weave_layer_15/batch_normalization_3/beta:0', 'weave_layer_15/batch_normalization_4/gamma:0', 'weave_layer_15/batch_normalization_4/beta:0', 'weave_layer_15/batch_normalization_5/gamma:0', 'weave_layer_15/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['weave_layer_15/kernel:0', 'weave_layer_15/Variable:0', 'weave_layer_15/kernel:0', 'weave_layer_15/Variable:0', 'weave_layer_15/kernel:0', 'weave_layer_15/Variable:0', 'weave_layer_15/batch_normalization_3/gamma:0', 'weave_layer_15/batch_normalization_3/beta:0', 'weave_layer_15/batch_normalization_4/gamma:0', 'weave_layer_15/batch_normalization_4/beta:0', 'weave_layer_15/batch_normalization_5/gamma:0', 'weave_layer_15/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['weave_layer_15/kernel:0', 'weave_layer_15/Variable:0', 'weave_layer_15/kernel:0', 'weave_layer_15/Variable:0', 'weave_layer_15/kernel:0', 'weave_layer_15/Variable:0', 'weave_layer_15/batch_normalization_3/gamma:0', 'weave_layer_15/batch_normalization_3/beta:0', 'weave_layer_15/batch_normalization_4/gamma:0', 'weave_layer_15/batch_normalization_4/beta:0', 'weave_layer_15/batch_normalization_5/gamma:0', 'weave_layer_15/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:5 out of the last 17 calls to <function KerasModel._compute_model at 0x7f3b472a4670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer TruncatedNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
            "  warnings.warn(\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['weave_layer_17/kernel:0', 'weave_layer_17/Variable:0', 'weave_layer_17/kernel:0', 'weave_layer_17/Variable:0', 'weave_layer_17/kernel:0', 'weave_layer_17/Variable:0', 'weave_layer_17/batch_normalization_3/gamma:0', 'weave_layer_17/batch_normalization_3/beta:0', 'weave_layer_17/batch_normalization_4/gamma:0', 'weave_layer_17/batch_normalization_4/beta:0', 'weave_layer_17/batch_normalization_5/gamma:0', 'weave_layer_17/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['weave_layer_17/kernel:0', 'weave_layer_17/Variable:0', 'weave_layer_17/kernel:0', 'weave_layer_17/Variable:0', 'weave_layer_17/kernel:0', 'weave_layer_17/Variable:0', 'weave_layer_17/batch_normalization_3/gamma:0', 'weave_layer_17/batch_normalization_3/beta:0', 'weave_layer_17/batch_normalization_4/gamma:0', 'weave_layer_17/batch_normalization_4/beta:0', 'weave_layer_17/batch_normalization_5/gamma:0', 'weave_layer_17/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['weave_layer_17/kernel:0', 'weave_layer_17/Variable:0', 'weave_layer_17/kernel:0', 'weave_layer_17/Variable:0', 'weave_layer_17/kernel:0', 'weave_layer_17/Variable:0', 'weave_layer_17/batch_normalization_3/gamma:0', 'weave_layer_17/batch_normalization_3/beta:0', 'weave_layer_17/batch_normalization_4/gamma:0', 'weave_layer_17/batch_normalization_4/beta:0', 'weave_layer_17/batch_normalization_5/gamma:0', 'weave_layer_17/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['weave_layer_17/kernel:0', 'weave_layer_17/Variable:0', 'weave_layer_17/kernel:0', 'weave_layer_17/Variable:0', 'weave_layer_17/kernel:0', 'weave_layer_17/Variable:0', 'weave_layer_17/batch_normalization_3/gamma:0', 'weave_layer_17/batch_normalization_3/beta:0', 'weave_layer_17/batch_normalization_4/gamma:0', 'weave_layer_17/batch_normalization_4/beta:0', 'weave_layer_17/batch_normalization_5/gamma:0', 'weave_layer_17/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['weave_layer_17/kernel:0', 'weave_layer_17/Variable:0', 'weave_layer_17/kernel:0', 'weave_layer_17/Variable:0', 'weave_layer_17/kernel:0', 'weave_layer_17/Variable:0', 'weave_layer_17/batch_normalization_3/gamma:0', 'weave_layer_17/batch_normalization_3/beta:0', 'weave_layer_17/batch_normalization_4/gamma:0', 'weave_layer_17/batch_normalization_4/beta:0', 'weave_layer_17/batch_normalization_5/gamma:0', 'weave_layer_17/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['weave_layer_17/kernel:0', 'weave_layer_17/Variable:0', 'weave_layer_17/kernel:0', 'weave_layer_17/Variable:0', 'weave_layer_17/kernel:0', 'weave_layer_17/Variable:0', 'weave_layer_17/batch_normalization_3/gamma:0', 'weave_layer_17/batch_normalization_3/beta:0', 'weave_layer_17/batch_normalization_4/gamma:0', 'weave_layer_17/batch_normalization_4/beta:0', 'weave_layer_17/batch_normalization_5/gamma:0', 'weave_layer_17/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer TruncatedNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
            "  warnings.warn(\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['weave_layer_19/kernel:0', 'weave_layer_19/Variable:0', 'weave_layer_19/kernel:0', 'weave_layer_19/Variable:0', 'weave_layer_19/kernel:0', 'weave_layer_19/Variable:0', 'weave_layer_19/batch_normalization_3/gamma:0', 'weave_layer_19/batch_normalization_3/beta:0', 'weave_layer_19/batch_normalization_4/gamma:0', 'weave_layer_19/batch_normalization_4/beta:0', 'weave_layer_19/batch_normalization_5/gamma:0', 'weave_layer_19/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['weave_layer_19/kernel:0', 'weave_layer_19/Variable:0', 'weave_layer_19/kernel:0', 'weave_layer_19/Variable:0', 'weave_layer_19/kernel:0', 'weave_layer_19/Variable:0', 'weave_layer_19/batch_normalization_3/gamma:0', 'weave_layer_19/batch_normalization_3/beta:0', 'weave_layer_19/batch_normalization_4/gamma:0', 'weave_layer_19/batch_normalization_4/beta:0', 'weave_layer_19/batch_normalization_5/gamma:0', 'weave_layer_19/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['weave_layer_19/kernel:0', 'weave_layer_19/Variable:0', 'weave_layer_19/kernel:0', 'weave_layer_19/Variable:0', 'weave_layer_19/kernel:0', 'weave_layer_19/Variable:0', 'weave_layer_19/batch_normalization_3/gamma:0', 'weave_layer_19/batch_normalization_3/beta:0', 'weave_layer_19/batch_normalization_4/gamma:0', 'weave_layer_19/batch_normalization_4/beta:0', 'weave_layer_19/batch_normalization_5/gamma:0', 'weave_layer_19/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['weave_layer_19/kernel:0', 'weave_layer_19/Variable:0', 'weave_layer_19/kernel:0', 'weave_layer_19/Variable:0', 'weave_layer_19/kernel:0', 'weave_layer_19/Variable:0', 'weave_layer_19/batch_normalization_3/gamma:0', 'weave_layer_19/batch_normalization_3/beta:0', 'weave_layer_19/batch_normalization_4/gamma:0', 'weave_layer_19/batch_normalization_4/beta:0', 'weave_layer_19/batch_normalization_5/gamma:0', 'weave_layer_19/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['weave_layer_19/kernel:0', 'weave_layer_19/Variable:0', 'weave_layer_19/kernel:0', 'weave_layer_19/Variable:0', 'weave_layer_19/kernel:0', 'weave_layer_19/Variable:0', 'weave_layer_19/batch_normalization_3/gamma:0', 'weave_layer_19/batch_normalization_3/beta:0', 'weave_layer_19/batch_normalization_4/gamma:0', 'weave_layer_19/batch_normalization_4/beta:0', 'weave_layer_19/batch_normalization_5/gamma:0', 'weave_layer_19/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['weave_layer_19/kernel:0', 'weave_layer_19/Variable:0', 'weave_layer_19/kernel:0', 'weave_layer_19/Variable:0', 'weave_layer_19/kernel:0', 'weave_layer_19/Variable:0', 'weave_layer_19/batch_normalization_3/gamma:0', 'weave_layer_19/batch_normalization_3/beta:0', 'weave_layer_19/batch_normalization_4/gamma:0', 'weave_layer_19/batch_normalization_4/beta:0', 'weave_layer_19/batch_normalization_5/gamma:0', 'weave_layer_19/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer TruncatedNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
            "  warnings.warn(\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['weave_layer_21/kernel:0', 'weave_layer_21/Variable:0', 'weave_layer_21/kernel:0', 'weave_layer_21/Variable:0', 'weave_layer_21/kernel:0', 'weave_layer_21/Variable:0', 'weave_layer_21/batch_normalization_3/gamma:0', 'weave_layer_21/batch_normalization_3/beta:0', 'weave_layer_21/batch_normalization_4/gamma:0', 'weave_layer_21/batch_normalization_4/beta:0', 'weave_layer_21/batch_normalization_5/gamma:0', 'weave_layer_21/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['weave_layer_21/kernel:0', 'weave_layer_21/Variable:0', 'weave_layer_21/kernel:0', 'weave_layer_21/Variable:0', 'weave_layer_21/kernel:0', 'weave_layer_21/Variable:0', 'weave_layer_21/batch_normalization_3/gamma:0', 'weave_layer_21/batch_normalization_3/beta:0', 'weave_layer_21/batch_normalization_4/gamma:0', 'weave_layer_21/batch_normalization_4/beta:0', 'weave_layer_21/batch_normalization_5/gamma:0', 'weave_layer_21/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['weave_layer_21/kernel:0', 'weave_layer_21/Variable:0', 'weave_layer_21/kernel:0', 'weave_layer_21/Variable:0', 'weave_layer_21/kernel:0', 'weave_layer_21/Variable:0', 'weave_layer_21/batch_normalization_3/gamma:0', 'weave_layer_21/batch_normalization_3/beta:0', 'weave_layer_21/batch_normalization_4/gamma:0', 'weave_layer_21/batch_normalization_4/beta:0', 'weave_layer_21/batch_normalization_5/gamma:0', 'weave_layer_21/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['weave_layer_21/kernel:0', 'weave_layer_21/Variable:0', 'weave_layer_21/kernel:0', 'weave_layer_21/Variable:0', 'weave_layer_21/kernel:0', 'weave_layer_21/Variable:0', 'weave_layer_21/batch_normalization_3/gamma:0', 'weave_layer_21/batch_normalization_3/beta:0', 'weave_layer_21/batch_normalization_4/gamma:0', 'weave_layer_21/batch_normalization_4/beta:0', 'weave_layer_21/batch_normalization_5/gamma:0', 'weave_layer_21/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['weave_layer_21/kernel:0', 'weave_layer_21/Variable:0', 'weave_layer_21/kernel:0', 'weave_layer_21/Variable:0', 'weave_layer_21/kernel:0', 'weave_layer_21/Variable:0', 'weave_layer_21/batch_normalization_3/gamma:0', 'weave_layer_21/batch_normalization_3/beta:0', 'weave_layer_21/batch_normalization_4/gamma:0', 'weave_layer_21/batch_normalization_4/beta:0', 'weave_layer_21/batch_normalization_5/gamma:0', 'weave_layer_21/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['weave_layer_21/kernel:0', 'weave_layer_21/Variable:0', 'weave_layer_21/kernel:0', 'weave_layer_21/Variable:0', 'weave_layer_21/kernel:0', 'weave_layer_21/Variable:0', 'weave_layer_21/batch_normalization_3/gamma:0', 'weave_layer_21/batch_normalization_3/beta:0', 'weave_layer_21/batch_normalization_4/gamma:0', 'weave_layer_21/batch_normalization_4/beta:0', 'weave_layer_21/batch_normalization_5/gamma:0', 'weave_layer_21/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timestamp: 2023-03-25 15:44:39\n",
            "{'dropout': 0.2, 'batch_size': 50, 'learning_rate': 0.0005}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'_batch_size_50_dropout_0_learning_rate_0.000500': 0.5,\n",
              " '_batch_size_50_dropout_0_learning_rate_0.001000': 0.5,\n",
              " '_batch_size_100_dropout_0_learning_rate_0.000500': 0.5313844642547073,\n",
              " '_batch_size_100_dropout_0_learning_rate_0.001000': 0.5,\n",
              " '_batch_size_50_dropout_0.200000_learning_rate_0.000500': 0.542247644387318,\n",
              " '_batch_size_50_dropout_0.200000_learning_rate_0.001000': 0.5,\n",
              " '_batch_size_100_dropout_0.200000_learning_rate_0.000500': 0.5,\n",
              " '_batch_size_100_dropout_0.200000_learning_rate_0.001000': 0.5}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#18 min\n",
        "import timeit\n",
        "start_time = timeit.default_timer()\n",
        "\n",
        "model_weave = dc.models.WeaveModel(n_tasks=12, mode='classification', dropout=0.2, learning_rate=0.0005, \n",
        "                                   batch_size = 50, batch_normalize_kwargs={'trainable': False}, \n",
        "                                   random_state=2, model_dir = \"./someDirectory/someFolder\")\n",
        "model_weave.fit(train_dataset5, nb_epoch=50)\n",
        "\n",
        "elapsed = timeit.default_timer() - start_time\n",
        "print(\"Fit time for this fitting at 50 epochs: \", elapsed)\n",
        "print(\"Timestamp:\", date_now, datetime.now(pytz.timezone('America/Vancouver')).strftime(\"%H:%M:%S\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XKrfA-ByOlz",
        "outputId": "440ea87b-90c0-470f-8bc2-4e50898f0218"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer TruncatedNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
            "  warnings.warn(\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['weave_layer_23/kernel:0', 'weave_layer_23/Variable:0', 'weave_layer_23/kernel:0', 'weave_layer_23/Variable:0', 'weave_layer_23/kernel:0', 'weave_layer_23/Variable:0', 'weave_layer_23/batch_normalization_3/gamma:0', 'weave_layer_23/batch_normalization_3/beta:0', 'weave_layer_23/batch_normalization_4/gamma:0', 'weave_layer_23/batch_normalization_4/beta:0', 'weave_layer_23/batch_normalization_5/gamma:0', 'weave_layer_23/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['weave_layer_23/kernel:0', 'weave_layer_23/Variable:0', 'weave_layer_23/kernel:0', 'weave_layer_23/Variable:0', 'weave_layer_23/kernel:0', 'weave_layer_23/Variable:0', 'weave_layer_23/batch_normalization_3/gamma:0', 'weave_layer_23/batch_normalization_3/beta:0', 'weave_layer_23/batch_normalization_4/gamma:0', 'weave_layer_23/batch_normalization_4/beta:0', 'weave_layer_23/batch_normalization_5/gamma:0', 'weave_layer_23/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['weave_layer_23/kernel:0', 'weave_layer_23/Variable:0', 'weave_layer_23/kernel:0', 'weave_layer_23/Variable:0', 'weave_layer_23/kernel:0', 'weave_layer_23/Variable:0', 'weave_layer_23/batch_normalization_3/gamma:0', 'weave_layer_23/batch_normalization_3/beta:0', 'weave_layer_23/batch_normalization_4/gamma:0', 'weave_layer_23/batch_normalization_4/beta:0', 'weave_layer_23/batch_normalization_5/gamma:0', 'weave_layer_23/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['weave_layer_23/kernel:0', 'weave_layer_23/Variable:0', 'weave_layer_23/kernel:0', 'weave_layer_23/Variable:0', 'weave_layer_23/kernel:0', 'weave_layer_23/Variable:0', 'weave_layer_23/batch_normalization_3/gamma:0', 'weave_layer_23/batch_normalization_3/beta:0', 'weave_layer_23/batch_normalization_4/gamma:0', 'weave_layer_23/batch_normalization_4/beta:0', 'weave_layer_23/batch_normalization_5/gamma:0', 'weave_layer_23/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['weave_layer_23/kernel:0', 'weave_layer_23/Variable:0', 'weave_layer_23/kernel:0', 'weave_layer_23/Variable:0', 'weave_layer_23/kernel:0', 'weave_layer_23/Variable:0', 'weave_layer_23/batch_normalization_3/gamma:0', 'weave_layer_23/batch_normalization_3/beta:0', 'weave_layer_23/batch_normalization_4/gamma:0', 'weave_layer_23/batch_normalization_4/beta:0', 'weave_layer_23/batch_normalization_5/gamma:0', 'weave_layer_23/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['weave_layer_23/kernel:0', 'weave_layer_23/Variable:0', 'weave_layer_23/kernel:0', 'weave_layer_23/Variable:0', 'weave_layer_23/kernel:0', 'weave_layer_23/Variable:0', 'weave_layer_23/batch_normalization_3/gamma:0', 'weave_layer_23/batch_normalization_3/beta:0', 'weave_layer_23/batch_normalization_4/gamma:0', 'weave_layer_23/batch_normalization_4/beta:0', 'weave_layer_23/batch_normalization_5/gamma:0', 'weave_layer_23/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fit time for this fitting at 50 epochs:  1086.8763577020004\n",
            "Timestamp: 2023-03-25 16:06:57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score_tox_model(model_weave, train_dataset5, test_dataset5, valid_dataset5, transformers5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOxT0gJUyOoi",
        "outputId": "23211b57-97b6-4966-bbb6-834d021bebb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<deepchem.models.graph_models.WeaveModel object at 0x7f3b3e9b1370>\n",
            "Train auc:  {'mean-roc_auc_score': 0.5, 'mean-balanced_accuracy_score': 0.5}\n",
            "Test auc:  {'mean-roc_auc_score': 0.5, 'mean-balanced_accuracy_score': 0.5}\n",
            "Validation auc:  {'mean-roc_auc_score': 0.5, 'mean-balanced_accuracy_score': 0.5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train a Dummy Classifer and 2 Machine Learning models from Sci-kit Learn for Comparison\n",
        "## Using RDKit descriptors as features for training"
      ],
      "metadata": {
        "id": "IM-wayC1ScV1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import libraries"
      ],
      "metadata": {
        "id": "N1rZUqALFPAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "metadata": {
        "id": "pai3FOypHNSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define scoring function for sklearn models"
      ],
      "metadata": {
        "id": "znVk764HS9hF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def score_sklearn_model(best_model, X_train, y_train, X_test, y_test, X_valid, y_valid):\n",
        "  y_train_pred = best_model.predict(X_train)\n",
        "  y_test_pred = best_model.predict(X_test)\n",
        "  y_valid_pred = best_model.predict(X_valid)\n",
        "\n",
        "  train_auc_score = roc_auc_score(y_train, y_train_pred)\n",
        "  train_balanced_accuracy_score= accuracy_score(y_train, y_train_pred)\n",
        "\n",
        "  test_auc_score = roc_auc_score(y_test, y_test_pred)\n",
        "  test_balanced_accuracy_score= accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "  valid_auc_score = roc_auc_score(y_valid, y_valid_pred)\n",
        "  valid_balanced_accuracy_score= accuracy_score(y_valid, y_valid_pred)\n",
        "\n",
        "  print(best_model)\n",
        "  print(\"Train AUC score: \", train_auc_score)\n",
        "  print(\"Train accuracy score: \", train_balanced_accuracy_score)\n",
        "  print(\"Test AUC score: \", test_auc_score)\n",
        "  print(\"Test accuracy score: \", test_balanced_accuracy_score)\n",
        "  print(\"Valid AUC score: \", valid_auc_score)\n",
        "  print(\"Valid accuracy score: \", valid_balanced_accuracy_score)"
      ],
      "metadata": {
        "id": "UpC3a54_UKSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train a Dummy Classifier"
      ],
      "metadata": {
        "id": "VfJTUxu9vZKM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#convert train_dataset2.X back to numpy array\n",
        "X_train_rdd=pd.DataFrame(train_dataset2_f.X).to_numpy()\n",
        "X_test_rdd=pd.DataFrame(test_dataset2_f.X).to_numpy()\n",
        "X_valid_rdd=pd.DataFrame(valid_dataset2_f.X).to_numpy()\n",
        "\n",
        "y_train_rdd = train_dataset2_f.y\n",
        "y_test_rdd = test_dataset2_f.y\n",
        "y_valid_rdd = valid_dataset2_f.y"
      ],
      "metadata": {
        "id": "2lbvY1FLD-u-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Grid Search for Dummy Classifier"
      ],
      "metadata": {
        "id": "dSPfalfrTWqV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grid_values={'strategy':['most_frequent', 'prior', 'stratified', 'uniform', 'constant']}\n",
        "\n",
        "dummy_clf = DummyClassifier(random_state=2,constant=1)\n",
        "dummy_grid = GridSearchCV(dummy_clf, param_grid = grid_values, cv=3, scoring='roc_auc', n_jobs=-1)\n",
        "dummy_grid.fit(X_train_rdd, y_train_rdd)\n",
        "\n",
        "print(dummy_grid.best_score_)\n",
        "print(dummy_grid.best_estimator_)\n",
        "print(dummy_grid.best_params_)\n",
        "\n",
        "dummy_params =dummy_grid.cv_results_['params'] \n",
        "dummy_mean_scores =dummy_grid.cv_results_['mean_test_score']\n",
        "\n",
        "df_grid_dummy=pd.DataFrame(\n",
        "    {'params': dummy_params,\n",
        "     'roc_auc':dummy_mean_scores\n",
        "    })\n",
        "df_grid_dummy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "rajxqYTcv8od",
        "outputId": "76d93b5c-fc09-44d1-aa86-71b212c838e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5041999235219068\n",
            "DummyClassifier(constant=1, random_state=2, strategy='stratified')\n",
            "{'strategy': 'stratified'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "3 fits failed out of a total of 15.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "3 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/dummy.py\", line 203, in fit\n",
            "    raise ValueError(\n",
            "ValueError: Constant target value should have shape (12, 1).\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.5        0.5        0.50419992 0.5               nan]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          params  roc_auc\n",
              "0  {'strategy': 'most_frequent'}   0.5000\n",
              "1          {'strategy': 'prior'}   0.5000\n",
              "2     {'strategy': 'stratified'}   0.5042\n",
              "3        {'strategy': 'uniform'}   0.5000\n",
              "4       {'strategy': 'constant'}      NaN"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6f74cc97-0613-4fdd-b567-8b288d1ec588\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>params</th>\n",
              "      <th>roc_auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{'strategy': 'most_frequent'}</td>\n",
              "      <td>0.5000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{'strategy': 'prior'}</td>\n",
              "      <td>0.5000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>{'strategy': 'stratified'}</td>\n",
              "      <td>0.5042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>{'strategy': 'uniform'}</td>\n",
              "      <td>0.5000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>{'strategy': 'constant'}</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6f74cc97-0613-4fdd-b567-8b288d1ec588')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6f74cc97-0613-4fdd-b567-8b288d1ec588 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6f74cc97-0613-4fdd-b567-8b288d1ec588');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Best Dummy Classifier"
      ],
      "metadata": {
        "id": "vhv2-a6wTd03"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = timeit.default_timer()\n",
        "\n",
        "dummy_bestmodel = DummyClassifier(constant=1, random_state=2, strategy='stratified')\n",
        "dummy_bestmodel_fitted = dummy_bestmodel.fit(X_train_rdd, y_train_rdd)\n",
        "\n",
        "elapsed = timeit.default_timer() - start_time\n",
        "print(\"Fit time for this fitting: \", elapsed)\n",
        "print(\"Timestamp:\", date_now, datetime.now(pytz.timezone('America/Vancouver')).strftime(\"%H:%M:%S\"))\n",
        "\n",
        "score_sklearn_model(dummy_bestmodel_fitted, X_train_rdd, y_train_rdd, X_test_rdd, y_test_rdd, X_valid_rdd, y_valid_rdd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uHVFBs1vVKX",
        "outputId": "ca533937-6bfc-443e-8409-203cdfe46eec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fit time for this fitting:  0.005295974002365256\n",
            "Timestamp: 2023-03-23 20:39:51\n",
            "DummyClassifier(constant=1, random_state=2, strategy='stratified')\n",
            "Train AUC score:  0.4983335844435275\n",
            "Train accuracy score:  0.3173690932311622\n",
            "Test AUC score:  0.49936291438076025\n",
            "Test accuracy score:  0.2869897959183674\n",
            "Valid AUC score:  0.5025353893113206\n",
            "Valid accuracy score:  0.29246487867177523\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Try a Random Forest Classifier"
      ],
      "metadata": {
        "id": "Fs6YKcNrT_fZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Grid Search for Random Forest"
      ],
      "metadata": {
        "id": "yOm7l6xITnLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grid_values={'n_estimators': [100, 200, 300],\n",
        "             'max_features': ['sqrt','log2', None],\n",
        "             'max_depth':[10, 50, 100]}\n",
        "\n",
        "rfc= RandomForestClassifier(random_state=2)\n",
        "rfc_grid = GridSearchCV(rfc, param_grid = grid_values, cv=3, scoring='roc_auc', n_jobs=-1)\n",
        "rfc_grid.fit(X_train_rdd, y_train_rdd)"
      ],
      "metadata": {
        "id": "9yT_H7ChT_Pa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(rfc_grid.best_score_)\n",
        "print(rfc_grid.best_estimator_)\n",
        "print(rfc_grid.best_params_)\n",
        "\n",
        "rfc_params =rfc_grid.cv_results_['params'] \n",
        "rfc_mean_scores =rfc_grid.cv_results_['mean_test_score']\n",
        "\n",
        "df_grid_rfc=pd.DataFrame(\n",
        "    {'params': rfc_params,\n",
        "     'roc_auc': rfc_mean_scores\n",
        "    })\n",
        "df_grid_rfc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 950
        },
        "id": "7Gxvc8eUfB2L",
        "outputId": "a24b47d1-5246-466e-afbd-8c1942460f61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7565303213315273\n",
            "RandomForestClassifier(max_depth=10, n_estimators=300, random_state=2)\n",
            "{'max_depth': 10, 'max_features': 'sqrt', 'n_estimators': 300}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               params   roc_auc\n",
              "0   {'max_depth': 10, 'max_features': 'sqrt', 'n_e...  0.750804\n",
              "1   {'max_depth': 10, 'max_features': 'sqrt', 'n_e...  0.754635\n",
              "2   {'max_depth': 10, 'max_features': 'sqrt', 'n_e...  0.756530\n",
              "3   {'max_depth': 10, 'max_features': 'log2', 'n_e...  0.741837\n",
              "4   {'max_depth': 10, 'max_features': 'log2', 'n_e...  0.749395\n",
              "5   {'max_depth': 10, 'max_features': 'log2', 'n_e...  0.753006\n",
              "6   {'max_depth': 10, 'max_features': None, 'n_est...  0.726987\n",
              "7   {'max_depth': 10, 'max_features': None, 'n_est...  0.732805\n",
              "8   {'max_depth': 10, 'max_features': None, 'n_est...  0.733958\n",
              "9   {'max_depth': 50, 'max_features': 'sqrt', 'n_e...  0.737478\n",
              "10  {'max_depth': 50, 'max_features': 'sqrt', 'n_e...  0.742312\n",
              "11  {'max_depth': 50, 'max_features': 'sqrt', 'n_e...  0.746509\n",
              "12  {'max_depth': 50, 'max_features': 'log2', 'n_e...  0.742596\n",
              "13  {'max_depth': 50, 'max_features': 'log2', 'n_e...  0.749017\n",
              "14  {'max_depth': 50, 'max_features': 'log2', 'n_e...  0.754880\n",
              "15  {'max_depth': 50, 'max_features': None, 'n_est...  0.727101\n",
              "16  {'max_depth': 50, 'max_features': None, 'n_est...  0.731699\n",
              "17  {'max_depth': 50, 'max_features': None, 'n_est...  0.736152\n",
              "18  {'max_depth': 100, 'max_features': 'sqrt', 'n_...  0.734068\n",
              "19  {'max_depth': 100, 'max_features': 'sqrt', 'n_...  0.740293\n",
              "20  {'max_depth': 100, 'max_features': 'sqrt', 'n_...  0.745129\n",
              "21  {'max_depth': 100, 'max_features': 'log2', 'n_...  0.742767\n",
              "22  {'max_depth': 100, 'max_features': 'log2', 'n_...  0.749042\n",
              "23  {'max_depth': 100, 'max_features': 'log2', 'n_...  0.754996\n",
              "24  {'max_depth': 100, 'max_features': None, 'n_es...  0.726275\n",
              "25  {'max_depth': 100, 'max_features': None, 'n_es...  0.731077\n",
              "26  {'max_depth': 100, 'max_features': None, 'n_es...  0.733638"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6bf1e820-8787-4ec9-9587-52f995b49afd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>params</th>\n",
              "      <th>roc_auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{'max_depth': 10, 'max_features': 'sqrt', 'n_e...</td>\n",
              "      <td>0.750804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{'max_depth': 10, 'max_features': 'sqrt', 'n_e...</td>\n",
              "      <td>0.754635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>{'max_depth': 10, 'max_features': 'sqrt', 'n_e...</td>\n",
              "      <td>0.756530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>{'max_depth': 10, 'max_features': 'log2', 'n_e...</td>\n",
              "      <td>0.741837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>{'max_depth': 10, 'max_features': 'log2', 'n_e...</td>\n",
              "      <td>0.749395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>{'max_depth': 10, 'max_features': 'log2', 'n_e...</td>\n",
              "      <td>0.753006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>{'max_depth': 10, 'max_features': None, 'n_est...</td>\n",
              "      <td>0.726987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>{'max_depth': 10, 'max_features': None, 'n_est...</td>\n",
              "      <td>0.732805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>{'max_depth': 10, 'max_features': None, 'n_est...</td>\n",
              "      <td>0.733958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>{'max_depth': 50, 'max_features': 'sqrt', 'n_e...</td>\n",
              "      <td>0.737478</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>{'max_depth': 50, 'max_features': 'sqrt', 'n_e...</td>\n",
              "      <td>0.742312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>{'max_depth': 50, 'max_features': 'sqrt', 'n_e...</td>\n",
              "      <td>0.746509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>{'max_depth': 50, 'max_features': 'log2', 'n_e...</td>\n",
              "      <td>0.742596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>{'max_depth': 50, 'max_features': 'log2', 'n_e...</td>\n",
              "      <td>0.749017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>{'max_depth': 50, 'max_features': 'log2', 'n_e...</td>\n",
              "      <td>0.754880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>{'max_depth': 50, 'max_features': None, 'n_est...</td>\n",
              "      <td>0.727101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>{'max_depth': 50, 'max_features': None, 'n_est...</td>\n",
              "      <td>0.731699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>{'max_depth': 50, 'max_features': None, 'n_est...</td>\n",
              "      <td>0.736152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>{'max_depth': 100, 'max_features': 'sqrt', 'n_...</td>\n",
              "      <td>0.734068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>{'max_depth': 100, 'max_features': 'sqrt', 'n_...</td>\n",
              "      <td>0.740293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>{'max_depth': 100, 'max_features': 'sqrt', 'n_...</td>\n",
              "      <td>0.745129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>{'max_depth': 100, 'max_features': 'log2', 'n_...</td>\n",
              "      <td>0.742767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>{'max_depth': 100, 'max_features': 'log2', 'n_...</td>\n",
              "      <td>0.749042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>{'max_depth': 100, 'max_features': 'log2', 'n_...</td>\n",
              "      <td>0.754996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>{'max_depth': 100, 'max_features': None, 'n_es...</td>\n",
              "      <td>0.726275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>{'max_depth': 100, 'max_features': None, 'n_es...</td>\n",
              "      <td>0.731077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>{'max_depth': 100, 'max_features': None, 'n_es...</td>\n",
              "      <td>0.733638</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6bf1e820-8787-4ec9-9587-52f995b49afd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6bf1e820-8787-4ec9-9587-52f995b49afd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6bf1e820-8787-4ec9-9587-52f995b49afd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Best Random Forest model"
      ],
      "metadata": {
        "id": "O8h0yi3kUBgH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = timeit.default_timer()\n",
        "\n",
        "rfc= RandomForestClassifier(max_depth=10, n_estimators=300, max_features = 'sqrt', random_state=2)\n",
        "rfc_bestmodel_fitted = rfc.fit(X_train_rdd, y_train_rdd)\n",
        "\n",
        "elapsed = timeit.default_timer() - start_time\n",
        "print(\"Fit time for this fitting: \", elapsed)\n",
        "print(\"Timestamp:\", date_now, datetime.now(pytz.timezone('America/Vancouver')).strftime(\"%H:%M:%S\"))\n",
        "\n",
        "score_sklearn_model(rfc_bestmodel_fitted, X_train_rdd, y_train_rdd, X_test_rdd, y_test_rdd, X_valid_rdd, y_valid_rdd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VArNisalNDQ9",
        "outputId": "f56f329f-f899-42c5-be2a-baf439cdf836"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fit time for this fitting:  12.03827597399868\n",
            "Timestamp: 2023-03-23 20:40:52\n",
            "RandomForestClassifier(max_depth=10, n_estimators=300, random_state=2)\n",
            "Train AUC score:  0.6525616580422157\n",
            "Train accuracy score:  0.7008301404853129\n",
            "Test AUC score:  0.5344320534853019\n",
            "Test accuracy score:  0.5637755102040817\n",
            "Valid AUC score:  0.542362105803081\n",
            "Valid accuracy score:  0.5696040868454662\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Try K Nearest Neighbor (KNN)"
      ],
      "metadata": {
        "id": "Jhk-K1hqufx2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Grid Search for KNN"
      ],
      "metadata": {
        "id": "5u6Gfdq9Ty9o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grid_params = {'n_neighbors':[3, 5, 7],\n",
        "               'weights':['uniform', 'distance'],\n",
        "               'metric':['euclidean','manhattan']}\n",
        "\n",
        "knn_grid = GridSearchCV(KNeighborsClassifier(), grid_params, verbose=1, cv=3, scoring='roc_auc')\n",
        "knn_grid.fit(X_train_rdd, y_train_rdd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "id": "6imTlXw8yXVl",
        "outputId": "c3717917-5b41-41cb-9924-fd56d9966764"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, estimator=KNeighborsClassifier(),\n",
              "             param_grid={'metric': ['euclidean', 'manhattan'],\n",
              "                         'n_neighbors': [3, 5, 7],\n",
              "                         'weights': ['uniform', 'distance']},\n",
              "             scoring='roc_auc', verbose=1)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=KNeighborsClassifier(),\n",
              "             param_grid={&#x27;metric&#x27;: [&#x27;euclidean&#x27;, &#x27;manhattan&#x27;],\n",
              "                         &#x27;n_neighbors&#x27;: [3, 5, 7],\n",
              "                         &#x27;weights&#x27;: [&#x27;uniform&#x27;, &#x27;distance&#x27;]},\n",
              "             scoring=&#x27;roc_auc&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=KNeighborsClassifier(),\n",
              "             param_grid={&#x27;metric&#x27;: [&#x27;euclidean&#x27;, &#x27;manhattan&#x27;],\n",
              "                         &#x27;n_neighbors&#x27;: [3, 5, 7],\n",
              "                         &#x27;weights&#x27;: [&#x27;uniform&#x27;, &#x27;distance&#x27;]},\n",
              "             scoring=&#x27;roc_auc&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(knn_grid.best_score_)\n",
        "print(knn_grid.best_estimator_)\n",
        "print(knn_grid.best_params_)\n",
        "\n",
        "knn_params =knn_grid.cv_results_['params'] \n",
        "knn_mean_scores =knn_grid.cv_results_['mean_test_score']\n",
        "\n",
        "df_grid_knn=pd.DataFrame(\n",
        "    {'params': knn_params,\n",
        "     'roc_auc': knn_mean_scores\n",
        "    })\n",
        "df_grid_knn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "dC3qiaqey5V5",
        "outputId": "2f2613f0-19f4-40db-9951-518e2828fb10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6551528942064407\n",
            "KNeighborsClassifier(metric='manhattan', n_neighbors=7, weights='distance')\n",
            "{'metric': 'manhattan', 'n_neighbors': 7, 'weights': 'distance'}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               params   roc_auc\n",
              "0   {'metric': 'euclidean', 'n_neighbors': 3, 'wei...  0.606032\n",
              "1   {'metric': 'euclidean', 'n_neighbors': 3, 'wei...  0.607623\n",
              "2   {'metric': 'euclidean', 'n_neighbors': 5, 'wei...  0.622180\n",
              "3   {'metric': 'euclidean', 'n_neighbors': 5, 'wei...  0.624383\n",
              "4   {'metric': 'euclidean', 'n_neighbors': 7, 'wei...  0.633738\n",
              "5   {'metric': 'euclidean', 'n_neighbors': 7, 'wei...  0.636420\n",
              "6   {'metric': 'manhattan', 'n_neighbors': 3, 'wei...  0.620686\n",
              "7   {'metric': 'manhattan', 'n_neighbors': 3, 'wei...  0.621612\n",
              "8   {'metric': 'manhattan', 'n_neighbors': 5, 'wei...  0.639259\n",
              "9   {'metric': 'manhattan', 'n_neighbors': 5, 'wei...  0.640857\n",
              "10  {'metric': 'manhattan', 'n_neighbors': 7, 'wei...  0.653125\n",
              "11  {'metric': 'manhattan', 'n_neighbors': 7, 'wei...  0.655153"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f4938440-d85e-4c78-9d2f-f5f539fb79ac\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>params</th>\n",
              "      <th>roc_auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{'metric': 'euclidean', 'n_neighbors': 3, 'wei...</td>\n",
              "      <td>0.606032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{'metric': 'euclidean', 'n_neighbors': 3, 'wei...</td>\n",
              "      <td>0.607623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>{'metric': 'euclidean', 'n_neighbors': 5, 'wei...</td>\n",
              "      <td>0.622180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>{'metric': 'euclidean', 'n_neighbors': 5, 'wei...</td>\n",
              "      <td>0.624383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>{'metric': 'euclidean', 'n_neighbors': 7, 'wei...</td>\n",
              "      <td>0.633738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>{'metric': 'euclidean', 'n_neighbors': 7, 'wei...</td>\n",
              "      <td>0.636420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>{'metric': 'manhattan', 'n_neighbors': 3, 'wei...</td>\n",
              "      <td>0.620686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>{'metric': 'manhattan', 'n_neighbors': 3, 'wei...</td>\n",
              "      <td>0.621612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>{'metric': 'manhattan', 'n_neighbors': 5, 'wei...</td>\n",
              "      <td>0.639259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>{'metric': 'manhattan', 'n_neighbors': 5, 'wei...</td>\n",
              "      <td>0.640857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>{'metric': 'manhattan', 'n_neighbors': 7, 'wei...</td>\n",
              "      <td>0.653125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>{'metric': 'manhattan', 'n_neighbors': 7, 'wei...</td>\n",
              "      <td>0.655153</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f4938440-d85e-4c78-9d2f-f5f539fb79ac')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f4938440-d85e-4c78-9d2f-f5f539fb79ac button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f4938440-d85e-4c78-9d2f-f5f539fb79ac');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Best KNN model"
      ],
      "metadata": {
        "id": "wmoof0kST-iQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = timeit.default_timer()\n",
        "\n",
        "knn = KNeighborsClassifier(metric='manhattan', n_neighbors=7, weights='distance')\n",
        "knn_bestmodel_fitted = knn.fit(X_train_rdd, y_train_rdd)\n",
        "\n",
        "elapsed = timeit.default_timer() - start_time\n",
        "print(\"Fit time for this fitting: \", elapsed)\n",
        "print(\"Timestamp:\", date_now, datetime.now(pytz.timezone('America/Vancouver')).strftime(\"%H:%M:%S\"))\n",
        "\n",
        "score_sklearn_model(knn_bestmodel_fitted, X_train_rdd, y_train_rdd, X_test_rdd, y_test_rdd, X_valid_rdd, y_valid_rdd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LmpqU9JzVtk",
        "outputId": "3c04a161-fbce-427b-bf53-7df4c0d86477"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fit time for this fitting:  0.014612596998631489\n",
            "Timestamp: 2023-03-23 21:10:38\n",
            "KNeighborsClassifier(metric='manhattan', n_neighbors=7, weights='distance')\n",
            "Train AUC score:  0.9946913340280212\n",
            "Train accuracy score:  0.9947318007662835\n",
            "Test AUC score:  0.5566939941599195\n",
            "Test accuracy score:  0.5318877551020408\n",
            "Valid AUC score:  0.5735519124306631\n",
            "Valid accuracy score:  0.5363984674329502\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# End of Notebook"
      ],
      "metadata": {
        "id": "C_a7iPx5EyVD"
      }
    }
  ]
}